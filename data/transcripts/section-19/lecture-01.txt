Before we talk about deep agents, we need first to understand a bit of taxonomy and to talk about what kind of agents do we have currently in production in the industry. So let me simplify this and give you how I view things. So we have the domain of agents and here are going to be all types of agents we have now in the industry. Now they can be agents, they can be agentic applications like for example this hybrid RAG architecture, where we have an LLM which is deciding which step to make, whether to make a search, whether to rephrase the query before the retrieval. And we have an LLM making a decision what's going to be the next step to be executed. Now under this umbrella of agents, we have here the ReAct agent where we have an LLM, which is deciding whether to use a tool or not. We execute this tool, then we either decide that we want to return a response to the user if we have enough information and if not, this agent continues an execute tool gets the result, the observation and simply goes on and on and on until it gets an answer. And by the way, this is what started this all, this all agent paradigm started from this ReAct algorithm, this ReAct loop here. Now when I showed you the taxonomy and show you how I view the words of agents, I refer to the ReAct agent as a shallow agent. Now the reason why I refer to it as a shallow agent is because this agent doesn't have the capabilities of going really, really deep. So for example, to perform a very deep and thorough research, even though it has a Search tool and a Wiki tool and a Tavily tool, if I want to make a decent research, this agent is not going to be enough. And the reason for it is from this agent design and from the reality of modern LLMs. So this agent is based on function calling. And in this decision arrow here we have here, there is a function call that the LLM makes in order to choose the tool to execute. Now don't get me wrong, there is no problem with function calling. Actually there is a bit of problem with function calling. I discussed it when I talk about code mode. But the inherent limitation of this agent, what makes it shallow and not being able to perform deep tasks is that it has a very limited context window. Now we know LLMs have context window. This is not new. But because of this architecture, every time we're going to be making a decision then to execute the tool, then to plug the result into the LLM, we are going to be bloating the context. And if we're going to have one iteration, it's going to be maybe reasonable. But as we have more iterations, this context window keeps growing and growing and growing and this is going to be leading to context rot. So we can have context confusion, context contradiction, context pollution, and a lot of things that eventually are going to degrade the LLM's performance and are going to get our agents to go off rails. Just to emphasize, I'm talking here about the use case where we have a complex task, a deep task where we need to continue and continue and continue and gather information and deduce and process. And we have something which is long running, not simply book me a flight. We have something much more complex like to implement a feature or to implement a deep research on a topic. So up until now I just talk about the degradation of the performance of the LLM, of the quality of the results. Of course it's going to be costing us more money because it's more tokens for each call we make. So the LLM call is going to be heavier. So it's going to contain more tokens, it's going to cost us more, it's going to be also slower. And this agent, this ReAct agent architecture, while it is amazing and it's the basis for basically everything, it's not really usable for complex tasks, those deep tasks. It is actually very good for shallow tasks that don't require a lot of iterations. And we actually have a lot of those kinds of agents in production. I've worked with many customers and a lot of them have this kind of architecture. And for a lot of use cases, it is actually enough and we don't really need more than that. Let's go and look at the world of agents again and we explain this shallow and ReAct part here. So now let's start to talk about deep agents. And deep agents are agents that are able to perform those kinds of long horizon tasks. Those tasks that are complex that require a lot of iterations, a lot of processing. Those agents are long running. They can run for minutes, for hours, even for days. They can get even user input. They can stop their execution, they can then resume it after they receive the user input. And those are what are called deep agents. So we have here deep research agents and here for example, we have Perplexity and we have here a deep research feature. And this is going to trigger a deep research agent run. Now deep research agents are very, very common today. So almost every other vendor have kind of support for research agents. Here we can see in Claude Code the research option. And here we can see in ChatGPT also a research option. And all of those are going to trigger deep agents that are going to perform research. And every one of them is implemented a bit differently by the vendors. We have also open source deep research agents, for example GPT Researcher, which at the time of recording this video is one of the most popular open source projects. And I actually review it in depth in my LangGraph course. Alright, let's go back to the taxonomy here. So we talked about deep research agents as an example, and we also have coding agents like Claude Code, like Devin, like Cursor, like Gemini CLI, and the list goes on and on because coding agents are actually one of the best examples of how deep agents can be very, very effective and useful for the industry and actually used by millions of developers. And here I'm going to be focusing on Claude Code because it is currently the leading coding agent. Now Claude Code is extremely good, it's very, very useful and it can actually be used for a wide variety of tasks which are long-running. They need to perform deep, they need scale. And this is the top coding agent at least when making this video. So we can go and ask Claude or any other coding agent to implement us an application or a feature in the application and those agents can go and run and actually accomplish it. They can go and not only code the required code but also to run tests, to test the application, to open up a browser, to take screenshots and to do the very same things that a normal software engineer would do. So those coding agents are going to be a subset of deep agents which are tailor-made for coding. So this is their specialty. And as a side note here, deep agents are what today drive innovation and they are the top tier technology we have right now. And it's actually very interesting to see the fact that LLMs now are becoming better and better, but currently their improvements are pretty gradual. So we don't have this huge leap of reasoning or other capabilities that we see from each new model that comes out. The quality is getting better. Yes, the reasoning is better, the capabilities are better, but it grows gradually. It doesn't grow exponentially. However, we are now at the point that abstraction on abstractions of agents, on agents in the application layer, if we know how to use those LLMs correctly, we can achieve some very impressive and very capable machines that can automate a lot of human work, which requires a lot of reasoning. Things that we once thought that are impossible because if I were to tell you five years ago, for example, that we are going to have a technology that is able to create a working pretty beautiful application from zero with AI with no human intervention, you would probably say that I'm crazy. And the point I'm trying to make here is that the application layer today, the application layer that implements those kinds of deep agents, this is what's driving now the technology, not the LLMs that are getting better, but the application layer that we build as developers on top of them, how to harness those LLMs. And today, this is what pushes the boundaries and pounds on the innovation. This type of work, the application layer work, this deep agents implementation. And let's go back to the discussion on deep agents and what makes an agent a deep agent. So there isn't really a clear definition, but an agent that is able to perform a complex task, in my opinion is a deep agent. And in order for an agent to go and perform these kinds of research tasks or coding tasks which are complex and require long running, we need to have certain capabilities of those agents that are going to make sure that we get a quality result. Now it all boils down to context engineering and smart context management, which is going to allow us to solve this problem of the context bloat and context accumulation. And it's going to help us scale those agents to perform a lot of things concurrently. And to achieve this and to achieve this capability of performing and executing on long horizon tasks, most deep agents implement the following. First, they have a planning tool which is going to plan what the deep agent is going to do. They also have a subagents capability. So this means they can spawn specialized workers that are going to work in isolated context and going to help the deep agent scale and perform a lot of tasks concurrently without bloating the context. Thirdly, they have a file system, where they can write intermediate results and shared states between those agents and everything is not going to blow to the context because it's going to be written to the disc. And thirdly, they have a monstrous system prompt. If you're going to pick up today one deep agent, it's going to probably implement those kinds of four ideas. And in the next video, I'll be diving and explaining those ideas, including show you implementations of it.