Hey there Eden here. And in this video I want to show you the gist of the MCP protocol I want to cover. What's the interaction between every component in the MCP protocol? So how does the client interact with the server? What's happening with the host and with the user and with the LM and how everything is playing together. So let's start with the diagram that we're seeing right over here on the left side we have the user, and the user is the one who's going to make queries into our application. Our application can be cursor windsurf can be cloud desktop and can be our agent that we wrote or any other agent which is deployed. Then we have the LM. So the application eventually is going to use an LM. So it's going to make requests to and we have the MCP server here. So the MCP server that we're going to be used that we're going to integrate into our application which supports MCP. Now you're wondering where is the client. So the client is actually residing within the application itself. And you can think about the application as the host of the MCP as well. So we have here the app which is going to perform the role of also the host. And it's going to also have the client. And the client is going to be connected to an MCP server. And in an app we can have multiple clients, and each client is going to be connected into a different MCP server. All right. So let's start at the very beginning. And this is when our application is loaded. So this is when we fire up cursor or when we fire up cloud desktop or our own agent. So the first thing that is going to happen we're going to make a connection to an MCP server or servers which are supported and integrated into the app. Now who is going to make those connections to the MCP servers? It's going to be the client inside the host, which lives in our application. So it's going to use the MCP protocol to initialize a connection, sending the messages back and forth. The MCP server is going to say that it acknowledges the client, and we're going to set the connection between the client and the MCP server. And if we have multiple MCP servers, then we're going to have a bunch of clients making connections into MCP servers here. Now when we initialize a connection, the server is going to let the client know which available tool does the server have. And let me reiterate on this. This is not only the tools, this is also including everything that the server exposes. So it can be all the resources that the server exposes and all the prompts and all the tools that the server exposes. I'm using tools here just for the example. If we're talking about the weather MCP server that we talked in the beginning of the course. So here's going to be the alert tool and the forecast tool. And the MCP server is letting to know the client which lives inside our application. And our host is going to let them know which available tools. So this is the interaction between the application and inside it, the clients and the MCP servers. And we see this is happening even before we have a user interaction. So this is when we fire up the application. Once we do that, we finish the MCP initialization and we finish setting up our application. So when a user is going to send a query to our application let's say cursor, then we are going to then send that message with the tools that we have to them. So because the application clients here, they know which tools the MCP servers expose, they're taking the tools that the MCP server returned that are available. And with the user query they are augmenting the user query with those tools. Now remember in the previous video I told you about the special prompt. So this is pretty much what's happening there. They're taking the original user query and they're listing the bunch of tools that are available. So now the Lem is not going to receive only the user's query. It's going to receive the user's query alongside with the available tools. So the LM now is going to respond. It's going to respond with an answer, or it's going to respond with a tool call that needs to be invoked. And remind you the MCP protocol is only working for tool calling LMS. So the tool call is going to have which tool needs to be called and what are the arguments that we need to call it with. So we have all the information about what needs to be executed. Now how do we execute that. So and this is the key difference by the way between the MCP and between frameworks like long chain. In long chain we execute everything in our application layer. And we will take that. And we're going to run everything inside the application. Usually what's happening with MCP, we are simply sending the tool call to the MCP server. So whether it's via Stdio or a server send event, we are sending to the MCP server which tool we need to invoke, which arguments do we need to send it. And the MCP server is going to run it. So everything is going to run now. The tool execution is going to happen in the MCP server. So it's not going to happen in the application in the graph or cursor application. It's going to happen in the MCP server. And this is a big advantage because once we do this we actually decouple everything. We decouple the MCP server and the tool execution from the agent itself. So the runtime of the server is what's going to run the tool. And this is going to help us if we want in the future to scale this out, maybe to deploy it on Kubernetes or in serverless and to monitor it in a different system. So this has a lot of advantages. And we'll talk about this when we talk about system design later in this course. All right. So the MCP server is now executing the tool it used for example the forecast tool and got us the forecast for California. Then it's going to send back the response to the application here. And and it's not really sending it to the application because it has this proxy of the MCP client. So the MCP client is going to handle the sending of the request and the receiving of the request, and the MCP client is then going to be integrated into our application, into our graph agent or cursor or whatever. So we got the answer from the MCP server. And now in the application layer we're going to make another request to the Lem. But it's going to be the user query with the response of the tool that was executed in the server. And now the Lem is going to decide whether we want to finish or whether we want to make another call. But let's say we want to finish. So what happens? The Lem sends its final answer and we receive it in the application layer. And then we return it to the user. And I want to note a very key difference between the Linkchain graph react agent and here the MCP flow. And we have a bunch of things that are together. And I want to note a very important difference in the Linkchain react agent. If we take it vanilla then the tools which are executing are going to execute within our app, within our agent. And if we'll take that and we'll integrate MCP into our graph agent, then what's going to happen is that we're going to run the tools in the MCP server. So we have here a decoupling of the tools component into a different service. And this is very useful. It's very helpful when debugging when logging helper for cost. It's helper for scaling. And I believe it's a better architectural decision to run everything in the MCP servers. And technically we can actually inside the graph tools, we can simply make dummy tools that will simply make requests into a different service, and we'll get a very similar behavior. However, the key difference here is that the MCP protocol is standard authorizing this, and it's going to give us one interface in order to do things. And this is something which is very, very cool. And I want to list another advantage of decoupling the tools from the agents itself. So the agent is going to be responsible for the orchestration. When to call the tool, and maybe to make another tool call, or to return a prompt to the user asking for feedback, whatever. So we decouple the logic of the orchestration from the tool execution. And by doing this decoupling, it actually gives us the point where we can actually update the server dynamically and maybe deploy it a new version of it, and we can set up that. The client is going to do this initialization not only once, but every once in a while, so that our agent is going to receive tools dynamically. And I think it's very cool and gives us the behavior of dynamic tool calling. So we don't need to redeploy our agent because our agent is going to have multiple initializations every once in a while, and it's going to receive the tools that it needs. This is another advantage. So I hope you enjoyed this video. And in the next video we're going to implement an MCP client inside our agent. And this is going to help us better understand these.