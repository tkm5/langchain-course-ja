Instructor: So in this video, I want to discuss some very good tips that can help you get started with prompt engineering and to manufacture some prompts that will produce you some awesome responses. Those tips are low hanging fruit. That means that it's super easy to incorporate them, and to implement them in your prompts. So once you do that, your prompt's going to be much, much better, and you'll see an improvement in your answers that you get from the large language model. So the first thing we need to consider is the context. Now the context is super important because it gives our prompt some contextual relevance and for generating coherent and accurate responses, we need to have the context. Now, if we don't provide the context to our prompt, then we are simply leaving this task of creating the context to the large language model, and the LLM will not provide the context that we may want. And we're simply leaving the LLM to guess what is the context, and that may generate a response that will be off topic and it won't be relevant or inconsistent with the goal that we want to achieve with our prompt. Okay, so this is example that we pass to the LLM sub context and we can see what kind of context the LLM deduces from the context that we gave it. So the prompt is the following. We want to tell the LLM to break down our prompt with contextual relevance. So the prompt is we want to generate a list of technical interview questions for a senior DevOps engineer position in a tech startup in a fast-paced culture working in the cloud, okay? So the task is to break down the prompt into contextual relevance. This is the task. And what comes after it, the entire sentence over here is the context. Now, what we can learn from the response that we got is that the LLM was smart enough to first recognize what is the context that we provided, and it was even able to label it as context and it was even able to label the task, which was to generate the technical interview question, which is super, super cool, and it is helping us to get a better result. So now I'm simply going to paste in the prompt that we want only the interview questions. Now let's review them. Now, we're not going to review all of the questions over here, but let's take a look at the first one. So how would you handle a sudden spike in traffic on the company's website? What steps would you take to ensure the website remains available and responsive to the users? So I personally come from a software engineering, DevOps, and cloud native application development background. And I can tell you right now that this interview question is very deep and you can talk only on this question for a half an hour, an hour, even two hours about the strategies, about how to implement, about use cases. So it's a very deep question, and even when I was interviewing candidates to a software engineering position, which also involved DevOps, this was a question that I asked it in a similar way or another. So just to summarize, the more contextual relevance that we add to our prompt, the better the results that we will get. So this is a very low hanging fruit and it's super easy to put and this will make the results much, much better. Okay, so the second tip is that we need to set a clear task that will not be ambiguous. So the task definition need to set a specific goal or objective for the LLM to achieve. So if we don't provide this goal that is clear, that is precise, that it is exactly what we want, then we simply leave it for the LLM to choose for us. So I like to think of it like when my wife sends me to the supermarket to buy apples. So okay, she didn't say what kind of apples, green apples, red apples. Does she want small ones, medium ones, large ones? I dunno. So I bring them apples and of course the result is not what she wanted and she's disappointed because I didn't bring her the apples she wanted. Now, in my opinion, being a prompt engineer is having great communication skills. So it is important to have communication skills with people, of course, because you want to know how to convey a message and you want people to understand what you want. So the same thing is happening with the large language model. If we want to be great in prompt engineering, then we need to sharpen and to improve our communication skills, but this time with the LLM. And the LLM likes to get the prompts that are having concise, clear and non-ambiguous tasks. Okay, so I think now is a good time to review an example of an ambiguous task because it will help us avoid those kind of tasks. So let's take a look at the prompt, improve the user experience of this e-commerce website. Now this prompt is ambiguous because it doesn't specify what aspect of the user experience needs to be improved or how should it be improved. This prompt doesn't provide any specific guidelines or metrics for evaluating the success criteria of the task. The task would be interpreted in many, many ways, and this could lead to confusion, lack of clarity, and lower performance overall. Okay, now let's change this prompt and let's make it clearer, make it less ambiguous and overall better. So now the task is identify and address specific pain points in the user experience of the e-commerce website to increase customer satisfaction and sales conversion rates. Now this version of the prompt is clearer because it specifies that the task involves with identifying and addressing specific pain points in the user experience rather than simply improving the user experience in a general sense. So this prompt also includes specific goals for the task, like increasing customer satisfaction and sales conversion rates. And this provides more concrete metrics for evaluating the success of the task. Now, this task was not ambiguous, it was clear and it was accurate because we were very specific. And as far as specificity, then it will refer to the level of detail that we include in our prompt to be more precise. The more specific the prompt will be, the more likely that the LLM will generate a targeted and accurate response. Okay, the final idea I want to introduce is iterations. Now iterations are crucial in prompt engineering and in the design of a prompt process. I'm a very big fan of this process. It is being practiced a lot in software. It's also introduced in the book "The Lean Startup." And basically to iterate is to repeat and repeat and repeat. And each time we repeat the process, we simply change it a bit and we simply make our execution better. So in prompt engineering, the iteration will involve refining the prompt that will improve it overall, okay? So it would also involve testing and evaluating the output. Each iteration should rely on the output of the previous iteration, and through this output, it should refine and make the prompt better. So this process will result in an optimized prompt according to our likings, after we iterate, we refine it and we have the perfect prompt that will give us the perfect result that we want. So we are going to finish this video soon, and I want that the takeaway from this video to be that the time we take to write a prompt is super important. And before we write a prompt, I know it's tempting to simply write something fast and click enter, but if we invest the time of prompt engineering our prompt and making it more precise, refining the tasks, adding the context, being specific, not being ambiguous, and constantly refining our prompts over iterations, then the results that we will get will be much better, and this will overall save us time. So that's what's really prompt engineering is about, in my opinion, to manufacture and to create this perfect prompt that will give you exactly what you want.