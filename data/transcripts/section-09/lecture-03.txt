Instructor: Large language models are trained on enormous amounts of data. It is believed that GPT-3 was trained of over a billion words. So just to give you a comparison. If you were to take a stack of a billion one dollar bills, this dollar stack would be over 67 miles up high. Now, this amount of data is directly translated to the knowledge of the model. So it is totally capable of answering questions and performing instructions without having some input data provided to it. So a zero-shot prompt is a type of prompt in which the model generates an output for that task it has not been explicitly trained on. So this means that the model is asked to perform a task without any specific training data, for example, for that specific task. Instead the model uses its preexisting knowledge to perform the task based on the information provided in the prompt. So for example, a language model that has not been trained on English text can still generate accurate outputs for French text despite it not being specifically trained on French. Now, let's take a look at an example of a prompt that is a zero-shot prompt. So the prompt is, "Create a list of the 10 must-visit cities "in the world in no particularly order." So you can see that we didn't supply it with any examples or any input data to indicate the answer. And it listed us a beautiful, coherent answer. So this is the zero-shot prompt. Now, as you go deeper and deeper into prompt engineering, you'll notice that the zero shot prompt is actually the most popular kind of prompt that people are using when they're getting into AI. Because at the beginning, you're starting to learning how to interact with the model. And it's super intuitive to simply ask it questions without providing it any examples or any way of thinking. So zero shot prompting do come with a bunch of limitations. For example, the accuracy. So what we're getting back from the model may not be exactly what we're looking for because we didn't supply it with any data or any guidance. So the scope might be limited, and we definitely have less control because it's only one prompt that relies on the model's preexisting knowledge, and it cannot be fine-tuned to any specific use case.