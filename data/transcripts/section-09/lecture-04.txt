Few shot prompts work by presenting the AI model with a small number of examples or shots of a particular task or concept, along with the prompt or instruction. So the model then uses these examples to generate or classify new data that is similar to the examples provided. Few shot prompts are particularly useful in scenarios where there is limited data available for a given task, such as a new language or domain where the data may be scarce, and they are useful for quickly adapting models to new tasks and domains, as they can be used to fine tuning existing models without requiring a large amount of new data. So in few shot prompting, we can have a one shot prompt where the model is given just one example of the results we want, and we have a few shots prompting, which is the model is giving a small number of the results that we want. So basically the one shot prompt is a subset of the few shot prompting. So because here n which is the number of prompts is equals to one where in a few shots prompting n is greater than one. Okay, so now it's time to have an elaborate example which will demonstrate zero shot, one shot, and few shot prompting and all of its use case. So we're going to compare the outputs that we get from the zero shot one shot and few shots. And we're going to see which one performed better according to our tasks. Okay. So what's our task? What you see right now is a discord server for an open source AI tool called Blue Willow. What you do in this tool is apply prompts. You write slash, imagine, then supply the prompt and this tool simply generates an image from your prompt. Now that's pretty standard. And it's the text to image technology that we're all familiar with. However, what we're going to do now to demonstrate the zero one shot and few shot prompts is to try all those techniques in a text to text manner that will generate for us the text to input blue Willow in order to generate the image. So our task is to generate a good description to paint our pictures. Okay, so let's start by writing a zero shot prompt. In the prompt we say write an image descriptions with adjectives and nouns of a Yorkshire dog running in the winter landscape of Brazil. Okay, so first let's analyze this prompt. Now we can see that the task is write an image description. We have a bit of context which is what to draw, which is a Yorkshire dog running in the winter landscape. In Brazil, we don't have any specific input data to process, and the output indicator is pretty much implicit. We are simply expecting the answer right away. Okay, so why is this prompt a zero shot prompt? Now it's a zero shot prompt because we didn't supply it with examples. And the AI model is simply now guessing and doing its best effort to provide us with an output that would like. But we can see that the output that we get is pretty good. I mean, we get an elaborate description that we can plug in, and it really describes an image. We'll soon also plug it in to discord and to see what image this generates. Okay. So now we want to refine our prompt to be using the one shot prompting technique to supply our prompt with one example of how we expect the output to be, and to help guide the AI model to output us what we want. Okay, so we're going to implement the one prompt prompting technique right now. So the prompt is write a compressed perfect image description with adjectives and nouns of a Yorkshire dog running in the winter landscape in Brazil. Then we gave it a bunch of nouns and adjectives blue dog, shimmering snow, etc. we then gave it the output indicator, which would simply tell the AI model that it needs to start working, and now we are expecting the answer from it. So the answer we get from it is better. We can see that first of all, the answer is more compressed. So this is because we also gave it the compressed context in the A prompt before. However, we can see that we are using much more adjectives and this looks better and concise. Okay, now in the last prompt, which is a few shot prompt, we're going to give it a few examples and we'll see what it is outputting us. Now we can see right over here that we supplied three different examples where the first example is saying that we want a dog which is blue, the second a red dog, and the third is a green dog. Okay. So the AI model understands that we want a color describing the dog. So let's take a look at the response that we get back from the model. And we can see that we got a vivacious violet Yorkshire dog. Okay. So the AI model understood from the examples we gave it before we gave it Blue Dog, Red dog, green Dog. So it understood that we want a color to describe the dog at the beginning. Now notice in the description we one time said the dog was sweating. We then said it was crying okay. And now it returned us that its fur is fluttering. Okay, so it's very, very cool that it understands exactly what we wanted because we wanted something to describe the dog. Okay. So this is very, very cool in my opinion. Okay. So now we want to take the output, which is an image description that we got from our AI model which was auto generated. And let's plug it in to Blue Willow and take a look. Which pictures do we get. Now the first one is the long description of the Yorkshire dog. We can see it right over here. Seems very cute, but the I didn't really know what we wanted. We didn't supply it examples. It was with a zero shot prompt, so the model pretty much guessed what we would expect to be a good answer. Okay. And it did a pretty good job. I mean, it had the creative freedom to do whatever it likes. So it gave us something very cool that we can work with. So this description was generated by the one shot prompt where we supplied one example of the adjectives and nouns that we want to use. So you can see it right over here. So in this context I don't think it's much better than the first one. So the first one did a pretty good job over here. And the last one is my favorite because we can see that what the AI model generated was exactly what we wanted, because we wanted the color of the dog in the beginning. So if we ran this query again and again and again, we would have gotten differently generated colors to describe the dog. So this is pretty much cool. Now let's compare all the photos all together. Altogether. So now we can really see the difference between the output that we got for the zero shot, the one shot and the few shot prompts. Okay. So in this case those pictures are not necessarily one better than another. And they're pretty much very similar to each other. However, the most important thing that you need to realize when it comes to few shot prompting is simply the number of examples that you give the AI model. The more answers and the more examples that you give it to train on your data, then it knows to adjust and to fine tune the results to give you something that you would like. Okay, so it would give it less artistic or freedom to do whatever it wants and guess and make the output more precise and to be more of your likings. Okay, so that's why it's important to know the difference between zero shot, one shot and few shot prompts.