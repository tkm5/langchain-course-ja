Let's now review the react prompt engineering technique. Like most of the prompt engineering techniques, it came from a research paper that you can see right now. Now react is basically based on reasoning and acting reasoning enacting. And this is where the name comes from. One part is reasoning the re and the act is for acting. So how does it relate to us humans? It is very natural for humans when we have a complex task, is to reason and think about the steps we need to do in order to accomplish this task, perform these steps, and then move on to the next step. So we break it down to multiple steps. We reason it down. We act upon those steps. And then after we complete everything, we can complete the entire task. So what those researchers found out is that if we take the chain of thoughts and we combine it with the ability to perform those actions and get, for example, information from external sources. The LM model can generate its task that it needs to do. This is the reason part, and we saw it earlier in the chain of thought that it is capable of doing that. And if it's able to perform and execute those tasks in overall, they will be able to resolve the entire task. So here we are combining the ability of the LM to generate its own task, the reasoning to track it and to update the plan accordingly, and to also execute those steps to get additional information from external sources. So, so this is found out as a very, very powerful technique. It is pretty much the basis for LM applications that are way more factual than ChatGPT and can use external APIs and tools. So this is pretty much what pioneered is something that is called link chain, which is a very popular framework for building LLM applications. So let's review and analyze this research paper that will demonstrate us the react paradigm. So we have here a prompt with a question. So aside from the Apple remote what other device can control the program of the Apple remote was originally intended to interact with. So here we can see that for the prompt above we got iPad which is not the true. This was the simple zero shot prompt, and with the chain of thought where we asked it to describe the way it was thinking, then the LLM responded us with some other outputs iPhone, iPad, iPod, etc. but it wasn't correct as well. So the last attempt was something which is called act only, and this is available only on Llms that can interact with the outside world. So there is the syntax of search. So basically right over here, um, the the prompt says to search for Apple remote and then to list its observations. So we can see over here the final result was yes, which is simply not the answer for the question. And basically all those three examples that we saw before are wrong. And we can see that when we had models that were based on the react paradigm, and the answer that we got from them was the correct answer, which is, by the way, the keyboard function keys. So let's now analyze what's happening with the reason and the acting of the LMS when it comes to react. Now with this particular problem, the LMS first comes up with a thought, a breakdown of what it needs to do. Like we simply know with the chain of thoughts. So the LMS says, okay, we need to search for the Apple remote and find what program it was originally designed to interact with. So it derived an act, something, something that it needs to do to access an external resource, which he received. The syntax of search for the Apple remote. Once he does that and searches for the Apple remote and gets information from it from outside sources, it makes an observation. And the observation was that according to the external source, then the Apple remote was originally designed to control the front row media center. Now this creates another thought to the LM model. This is similar to the chain of thoughts, but we can act upon those thoughts. The second one is that okay, now the LM knows that there is something to do with the front row media center, and that's why it's determining that the next act should be to search for something which is called the front row. For some reason. Now it observed that it didn't find anything. It did find something similar to front row software. So now it creates a new thought that it should examine the front row software. So the act deriving from it would be to search for the front row software. It makes one observation after upon the act and it not so it's not so relevant. But the final thought is what is bringing us closer to the answer, because the final thought is that the front row software is controlled by the Apple remote or the Apple key function keys. So this is from the external sources that we got on the previous step. So from this it understands that the answer is the keyboard function keys. So this is mind blowing because it is simulating the human thought. And if I needed to answer this question this is exactly what I would have done. So this is crazy crazy crazy. And this is super powerful. Now you might be thinking, whoa, this is some sort of magic. How does this happen? I mean, I haven't really told you what's what's happening behind the scenes. I mean, how how does this even work? So basically, what's happening is simply integrating some kind of code with the chain of thoughts we saw earlier, that the chain of thoughts can create thoughts and can create steps, and the LM is totally capable of generating those steps. The next thing to do is to simply act upon those steps. So this can be done by code. And it's not even that hard as you may think, because doing so only involves taking the output step, which describes what we need to do, and looking up for keywords like search and finding the topic. So this can be easily done by code. And then to rerun the prompt with the observations that we got and do it over and over until we get the solution. So this is pretty much mind blowing. And this is exactly the basis for something which is called the link chain, which is the most popular framework right now to implement LM applications which can handle and do complex stuff like interacting with external sources, persisting data, and a lot more.