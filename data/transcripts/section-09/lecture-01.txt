Instructor: First, it's important to start with what is language modeling? So this is the formal definition from Wikipedia, which talks about a distribution of probabilities over a sequence of words. So if I'm going to bring this down to earth, language modeling is the task of predicting what word will come up next. You can think about it like a super, super smart autocomplete. So if we have a sentence like the dog wigged its, and then a collection of words, then according to this sentence, the language model for each word that you see right now has a probability. And what it would output for you is the highest probability, that it's correct. So now let's review the formal definition of a language model. So for that, you don't really need to know computers and science, you'll see it's very, very intuitive. So given a sequence of words, we'll mark the words X1, X2, and Xt. So you can simply map each X to the word in the sentence previously. We want to compute the probability distribution of the next word, which is Xt+1. Because we had so far X1 until Xt, those are the words in our sentence, and we want to know what is the probability of the word Xt+1. Cool. So P is the notation for probability. So in this notation, you see right now we want to ask, "Hey, what is the probability of the next word, which is Xt+1, given this is the long line that you see right here, that we had the sentence X1 until Xt before. And Xt+1 needs to be a word in our vocabulary." Now, our vocabulary is an object, which is notated as V for vocabulary. So if we just summarize what is a language model, then it's simply the idea that we have a sentence, a couple of words that come together, one after another, and we want to guess what will be the next word. So it's super, super similar like autocomplete, just like we know from our day-to-day lives, like when we write a text message and we have a suggestion, so it's based on a language model. The same thing when we search for something in our search engine. So what's a large language model which is all the hype right now? So a large language model or abbreviated, LLM, is simply a language model like we saw before that was trained on a huge amount of data. So you can think about it as a model, a language model that was trained on so much data that is pretty much very, very good at calculating those probabilities. So every time you write a prompt, then what you basically do is give an input of words for the LLM and the LLM simply now guesses and make its best effort in order to output you the next word, one after another. So it calculates the probability and gives you the word with the highest probability in the context of the input you provided. So it simply guesses word after word after word, what you are expecting. Now, this is why LLMs can sometimes output us something that is so farfetched from reality and simply not true, because it's simply guessing the probability and simply relying on that. So that's the entire concept of LLM.