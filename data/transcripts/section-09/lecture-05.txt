Large language models with 100 billion parameters can achieve great things. They can output us strong results from a wide variety and range of tasks, and they can do it even with no training or little training by us. However, even the largest LLM model can still struggle with certain kinds of problems. Those multi-step reasoning tasks, such as math word problems and common sense reasoning that are easy for us humans are not so easy for the models. So for that, researchers at Google came up with a method which is called chain of thought and chain of thought. Prompting aims to improve the reasoning abilities of the llms, and this method enables the models to decompose multi-step problems into intermediate steps, allowing the model to solve complex reasoning problems that are not solvable with standard prompting methods or Chain of thought, or abbreviated Cot, is breaking down a problem into a series of intermediate reasoning steps, and it significantly improved the ability of llms to perform complex reasoning. So by breaking down a complex problem into smaller, more manageable steps, the chain of thought allows llms to reason more accurate and to have better efficiency. So, like most prompt engineering techniques, the chain of thought technique was first introduced in an official paper for prompt Engineering. You can see the paper right over here and its URL also listed in the course's resources. Okay, so let's start introducing this topic from the examples that are noted in this paper over here. Okay, so we want to start with the standard problem prompting and introduce the problem and to see that it's not sufficient. Okay. And we'll see how the chain of thought prompting resolves this insufficiency. So we have two prompts over here that we asked our AI model. The first one is a question and it's kind of a riddle. So Sean has five toys for Christmas. He got two toys each from his mom and his dad. And how many toys does he has in total? So the AA model A responded with nine, which is the correct answer. Okay, so basically he had five toys already. Two he got from his mom and two he got from his dad. So it's five plus two plus two. This is great. Now afterwards those researchers, they asked another riddle which is kind of similar. It has the same thought process. So the question is the prompt is John takes care of ten dogs. Each dog takes five hours a day to walk and take care of their business. How many hours a week does John need to take care of his dogs? So the AI model outputted. That was 50, so probably the calculation was ten times five, which outputted 50. Now this is not the correct solution. The correct answer for this is 35 hours. So in the standard prompting that we saw right now, which is actually if we classify it, it goes to the topic of zero shot prompting. Then we got insufficient answers for our questions. Okay. So we had kind of a limitation over here. So the paper here introduced this limitation with the standard prompting. And here was an example of a zero shot prompting. And the paper suggested that there is a new way of prompting technique which is called change of thought. So chain of thought is actually pretty simple. What we want to do is guide the model to solve the problem, like we as humans solve those problems. And by doing that, we'll make the model smarter and better, and hopefully it will output us the answer that we want and the correct answer. Okay. So in the example over here, what those researchers did, they took the first question with the toys and they gave an example answer. Okay, so you can think of it as a one shot prompting. Okay. But they did more than that. They also supplied the chain of thought how we as humans solve this problem. So in their answer, they said that John started with five toys. He got two from his mom and two from his dad. So the calculation should be four plus two plus two, which is nine. Okay, that's why the answer is nine. Okay. And then they asked the same question again. And it turned out that the model was smart enough to take the chain of thought that the researchers applied to it for the previous question, which was kind of similar, and to apply this chain of thought in the next answer. Okay. So you can see that the second response with the chain of thought prompting. Then the model got the correct answer and it actually supplied the steps that it made in order to get to that answer. Okay, so the AI model outputted that John took care of ten dogs. And because each dog takes half an hour a day to walk and take care of. So the calculation should be ten, which is ten dogs times the time it takes to take care of them, which is five hours per day. So if we have five hours per day for taking care of the dogs and we have seven days in a week, then the calculation should be five times seven, which is going to be equal to 35. Okay. So the thought process was pretty much the same over here with both questions. It was to take the calculation that we need to calculate and to break it down to two sub calculation. Okay. So yeah. So that was the chain of thought prompting in the research paper that you see below. Chain of thought is a significant development in prompt engineering and LM usages because it allows the LM model to approach problem solving in a more human like manner, and it allows the models to break down complex problems into intermediate steps that are resolved individually. So this is a major step in prompt engineering which opens us to solving a lot more problems. So we saw in earlier videos that we had zero shot, one shot and few shot prompting. So in chain of thought we actually have something very similar. Okay. So we have something which is called a zero shot chain of thought. So in this kind of prompt we simply add to our prompt something like let's think step by step and then the model will output the answer while explaining what it gets to be the steps. Okay, so we did not supply the reasoning engine to the model, and we let it have its creative freedom and choose for us. Okay. And if we integrate few shots chain of thought prompting, then we simply in our prompt supply the model with the answer we want and explain to them what are the steps and what are the chain of thought that we used to resolve those steps? And how did we come up with this answer. And the model takes this data, processes it, and then outputs the correct answer. Okay. So zero shot chain of thought can be actually beneficial. Okay. And you can actually see the reasoning process of the AI model. Okay. But it will have no prior knowledge. And in the few shot change of thought prompt we will attach to our prompt the real answer that we're expecting in a very similar problem and explain how we got to this answer and the AI model will take it, will process it, will learn it, and then the model will be able to deduce the chain of thought that we supplied it to other problems, and will be able to apply this chain of thought and will be able to solve similar, but not really the same problems in the way that we wanted it to resolve it.