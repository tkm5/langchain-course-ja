Hey there. Eden here. And in this video I want to talk about context engineering. Now, if you've been working with AI agents and probably coding agents like Cursor and Cloud Code, or maybe you even developed AI agents for your companies or for your own use, and you probably know that basically, it all boils down to a prompt being sent to an LLM and a lot of engineering around it. So there is some truth for calling applications like cursor and cloud code, just wrappers around llms. However, to build really good wrappers requires a lot of deep knowledge and a lot of engineering work because we know that those calls to those llms, they come with context. And this context comes from various sources. Context can come from the developer of the application. It can come from the user. It can come from the previous interaction of the user, from tool calls and other external data. The number of context sources is is increasing every day and sending the correct and relevant context to the LM. It's not quite as simple as we thought it was in the early days. We thought, hey, we have prompt engineering and we'll write some fancy prompts and this will fix all of the problem. However, the problem is this is that prompts are static. However, those pieces of context are extremely dynamic, and if they're extremely dynamic, then in order to construct the correct contents, we need to have a dynamic system as well. So it's not just a static prompt. And this is why we're entering the realm of context engineering. And it's the natural evolution of prompt engineering. But it's a much deeper concept. Now we all know the saying garbage in, garbage out. And this is a common reason why agentic systems don't perform as the way they should, because they're simply not provided with the right context. Llms cannot read our minds. We actually need to give them the right information. And by the way, it's not always information and data. Sometimes we need to give them the correct tools so they'll be able to fetch other information and take some actions and do some stuff for us, and then they'll achieve the task. So let's focus a bit on agents. And Llms are becoming better and better. And this is not new. They can reason very very well. And we have tool calling and we can build with it. Very cool functionality of AI agents which are running tools, invoking those tools, getting the output of those tools and then running in a loop until they finish a task. However, when it comes to a long running task and a complex task, we often accumulate the feedback from the tool calls, and this means that the context window is going to keep growing and growing, and to have lots of tokens being filled up with all the tool calls results. So this can cause a lot of problems, and it can of course exceed the size of the context window Though, and it can increase the cost, the latency. And by the end of it, it's eventually, if we're not going to do anything about it, it's going to degrade the agent performance, this degradation. There are many reasons. So for once we can have a context poisoning. So this is when one tool call or one call introduces a hallucination that makes it into the context. And it's starting now to degrade the system. Another thing that can happen is context. Confusion is that when we introduce some unnecessary context that is going to influence the response. So this is context which is not needed to the task. And of course there is the possibility of a context clash when parts of the context contradict each other. All right. So let me summarize this video in a couple of sentences. We discussed what is context engineering and in a very simple term is simply a way to give the LLM the correct context. We discussed. Where did this concept evolve from prompt engineering and why is it specifically important for agents? And in the next video we're going to discuss some techniques. And those techniques are going to give eventually the LM better context. Now some of those techniques are going to be on the application developer side. So for example, developers of applications like cloud code will implement those kinds of solution. However some of those techniques are on the user side. So we as users of cloud code has a lot of influence on the answer that we get and the context that we're going to supply the LM eventually. So this means that even non developers need to know context engineering and need to understand this principle if they want to get better responses and better answers from their AI systems and AI agents. Just to finish, an excellent example of context engineering techniques and how to implement them from both the developer side and both the user side is coding agents like cloud Code. And this is what we're going to be discussing. In the next video, I'll be discussing how to better engineer our context.