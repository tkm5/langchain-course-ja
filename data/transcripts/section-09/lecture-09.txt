Hey there, Eden here. And in this video we're going to be discussing system prompts and their importance in context engineering. And I know you've probably read it a thousand times on Twitter and on LinkedIn. That system prompts are important and you should work on them, and you should iterate on them. And you should make them really, really good. And saying having a good system prompt is the most generic advice in AI engineering. So instead of saying to you again that system prompts are important, I want to show you some example system prompts of the state of the art agents out there. So this repository here contains all of these system prompts, leaked system prompts of all of the famous state of the art agents. And most of the agents here are coding agents like cloud code, like cursor, like Devin. But you can find here other agents like the comment assistant in the comment browser by perplexity. And this is a very popular repository here at the point of recording it. It has almost 90,000 stars. Let me go here, for example, to cloud code. And here you can see the cloud code system prompt. We can see we have here almost 200 lines of code here. And here we can see all of the tool descriptions. And this is 500 words. Now all of the tool descriptions here are going to be injected into the system prompt here. Let's go have a look on cursor and let's check out the cursor agent. This prompt is also around 200 lines of code. You can see here the structures. And let's go and check out Devin. And Devin has 400 lines of code here in the prompt here. And the goal of this video is not to go and to analyze each prompt and to tell you all of the techniques they used in the prompts, because we can have an entire course only dedicated to that. But my point here is just to show you that it's important, and this repository is continuously being updated because the system prompts keep evolving and because llms are evolving all the time, so does the system prompts. And a lot of engineering resources are going to keep curating those system prompts and making them better and better. And this is an iterative process. All right. So I hope by this part of the video you agree with me that system prompts are important. So I want to talk about a bit of best practices when curating and crafting those system prompts. And I like the analogy of a system prompt to giving someone directions to go somewhere. If we go say something like go over there, They'll be confused. They won't know where to go. However, if we give them a 50 page manual with every possible turn and street, and we're going to overwhelm them with information they won't be getting where they need to go as well. So here we want to be clear. We want to be specific. And we want to give just enough information to get there where they need to go. So here's comes the hard part. We need to find that sweet spot. So when we're going to be writing system prompts, we're looking to what anthropic refer to as the Goldilocks zone. So it's going to be not too vague, not too detailed, but it's going to be just about as right. So you can see this in this scale over here we have on the very far left too specific and on the very far right too vague here. So we want to be right here in the middle. So let's break down how this a specific prompt here at the very far left here. And the core problem here is that we are treating the LM like a deterministic state machine rather than an intelligent agent. And we hard code logic. So we can see here stuff like if user intent is incident resolution, ask three follow up questions. So why do we need exactly three questions. What if two is going to suffice? Or what if we need five questions here. And we can see we have exhaustive enumeration. So we list every possible escalation scenario which is impossible to complete. And it forces the model through predetermined paths that may not match the reality of the input. And it's also going to be a maintenance nightmare, because every new edge case is going to require to have prompt modification here. And by the way, if we have predetermined steps and maybe an agent, an autonomous agent here is not going to be the answer. Maybe we just need an authentic workflow. All right, let's move to the opposite end of the spectrum where we have a very vague prompt. And the core problem here is that we provide insufficient signal for consistent behavior. So in this example we have no actionable guidance. So assist in a manner consistent with the principles of essence of the company brand. What are those principles we have here this false assumption of a shared context. And this assumes that the model knows the bakery and knows the customer service norms, which it actually doesn't, and it really has undefined boundaries. And the statement here escalates to a human if needed. When is it needed? So the model needs to guess this. And in this prompt we have no framework. We have no structure of approaching problems in a systematic way. So this is going to lead us with inconsistent behavior, which means that different runs is going to produce us wildly different approaches to solve the same problem here. And the main problem of this prompt is that it's essentially saying something like, do the right thing without defining what right really means in the context. Here we start by providing clear identity and scope. And this immediately going to establish boundaries because it's customer support. It's not marketing. It's not sales. And it's going to give the domains. So it's going to be borders and basic questions but not complex business operations. And then we go and we empower rather than constraint. So instead of prescribing and telling exactly which tool to use in which situation establish a goal which is efficient in professional resolution. And the heuristic here is that we believe that the agent is going to select the appropriate tools when needed. And here we also provide a reasoning framework and not a flowchart. So we have this four step response framework where it first needs to identify the core issue to gather the necessary context, to provide clear resolution and to confirm the customer satisfaction. Now this is guidance. It's something which should work across a lot of scenarios. And it's not some rigid branching logic like we had before here. Now in the last part of the system prompt, we establish here clear boundaries. And we have here some principles to follow through. So if we have multiple solutions we need to choose the simplest one. So this is a heuristic. So it's something we're hoping that it's going to be the right thing to do. And it's actually, by the way, reminding me in computer science, a greedy algorithm approach. Now I want to elaborate on why this prompt here is much more superior than the other system prompts. The very specific prompt tried to do the thinking for it, and actually it made it worse when situations does not match the exact script here, and the too vague prompt didn't give the LM enough to work with. However, the the prompt, it really took advantage of what state of the art large language models are really, really good at, which is to recognize patterns and to apply general rules to specific situations here. Now, the prompt handles new situations very well because it teaches principles instead of giving specific rules. So it should work even when it's going to encounter something new, because it has the framework which is still going to work. The middle prompt also is very efficient, so it doesn't waste any words. So each guideline covers many different situations. The principles here are compressed. So instead of having hundreds or thousands of edge cases we have simple sentences here. And we don't have anything which is repeated or overlapping instructions which can cause contradiction instructions to the large language models. Hey there. Even here popping out. So I hope you enjoyed this video. I just want to reiterate on the videos goals. The first goal is to simply show you that system prompts are really, really important and I hope you got this message. And the second one is to give you an example of a good system prompt and compare it to some bad system prompts. So we'd love to get your feedback on this video. And if you like this kind of content, please let me know and I'll be making more theoretical content like this.