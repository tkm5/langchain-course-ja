So I want to add here some real world searching over the internet. So I'm going to import from Tavileh, the Tavileh client. So let me now go and initialize this Tavileh client. So I'm simply going to create a variable called Tavileh. And I'm going to initialize the client. And this client when it's going to initialize and it's going to be looking for an environment variable called Tavileh API key. So this is where we put in our dot env file the API key. So everything should be working right now. So let me now instead of returning the Tokyo weather is sunny, let's go and run the actual search query and let's return the results. We'll be doing it with Tavileh. Search and search need to receive an argument called query and query. Here is going to be equal to our query, which is the input to our search function. Amazing. So let's go and run it now. And it's going to have now a real searching capability. So we'll just wait for it to finish. We can see now it's searching over the web. And once we have an answer, we'll head up to Lenox-smith to review again the traces. So everything now should be very similar. But if we go now to the search execution here, we can see that instead of returning a static string here, we're actually going to output some real information of the weather in Tokyo. And this is an example of a search made. And it got the information from the weather API. And here you can see all the information of the weather. So it also provided us with other results and other answers. So it provided us with the top results here. And if we want we can control this parameter of how many results you get. And if I go to the last LM response here, we can see now we get a different answer, which is a much more elaborate answer here, which is grounded on real time information, which we got through research. All right. So now let's go and let me change now the query to be what I showed you in the demo. So now let's have a look and let's see if we can get some job openings for link chain professionals. So let me go back to the code here. And here in the message I'm going to tell the agent that I want to search for three job postings for an AI engineer in chain in the Bay area in LinkedIn, and to list all of their details here. And don't worry about this prompt if you'll check out the repo in the videos resources, you can simply copy and paste it. Anyways, let me go now and let's go and run this. And we can learn from this log over here that we are running now. LinkedIn is running the search tool here. It's running it five times with five different queries. So the first query is to look inside LinkedIn.com slash jobs looking for LinkedIn, Bay area, San Francisco San Jose AI engineer. So we have multiple search queries here. All right. We got now a result. We can see now here in that it finished. We can see here a it's all printed out. Not very nicely. So let's go and open it. And let's check out the trace. And now we can see our input our query. And notice that in the output of the LLM in the AI response here we get multiple tool calls. So the AI decides to call multiple tool calls. And it's going to execute them in parallel. So this is because function calling in GPT five supports multiple function calling and will be elaborating it later in the course. This is an example of one tool call. This is an example of another tool call. And we have here a five tool course. And the final request to the MLM contains all the tool calls and all their answers. And let me go here and down. And let's see the final answer of the LM. And here we got the answer. So and we got here all of the job postings on LinkedIn and the URL to LinkedIn. Notice that some of them are no longer accepting candidates. But this is the final response here of the LM. All right. I want to go back to the code now. And I want to discuss now a best practice when using LinkedIn. So in our example we wrote a custom tool and used the SDK inside that tool. However, this will require us as the developers to know every bit and byte and to know how the SDK is working. And in fact I do not know exactly all the internals of the SDK so heavily because it has a LinkedIn integration. The team, they wrote a package link chain which takes the SDK and wraps it as a chain tool. And you can trust you should trust the vendor, in this case the team, to write a much better description, much better arguments, and they can do a far better job writing the link chain tools than we do here. So what I'm going to do right now, I'm going to remove the custom tool, and I'm going to use the built in Tavileh search tool that the Tavileh team wrote. So let me add link chain Tavileh just to make sure I have this package installed. And let me now remove all of these search tool. We do not need it. Also the Tavileh client. And let's instead of this import let's right from link chain underscore tavileh let's go and import. It's called Tavileh search and Tavileh search. Let's go and check out the implementation is a base tool here. So it's a link chain tool. So let me go back now. And because this is already a tool all I need to do is to initialize this object. I won't be sending it any custom arguments. So let's go now and run it again. And I'm going to fast forward this because it may take some time. And let me go back now to link and let's check out this trace. So notice here that the name of the tool here is called underscore search. And this is how Tavileh named their tool. And our name was search. And you can compare it with the previous trace. And let's go and check out an example of an execution here. And we can see here we have the query like we had before, but we have here some extra arguments that the LM decided to make with the tool call. So those are arguments that I didn't know about. So they are include domains linkedin.com. So this is probably going to say to to really to only get results from LinkedIn.com. And it has an extra argument which is called search depth which is advanced. And I will be explaining this further in the course because we'll be seeing much more examples with David. What is this argument here? But the point I want to show you here is that we are getting a much more elaborate tool calls here. And while the answer is very similar to what we executed before, however, it's a bit more accurate now because the agent was able to make much more specific tool calls, which should ground the answer in better sources. All right, let me go now and let me bring back the implementation with our custom tool here, and let me push everything to the repository and I will be linking everything in the videos resources. All right. So let me go now and add everything into git. And let me now see all the files here. So let me now commit everything. Let me right in the message intro to search agents and let me push it. Sorry. Let me set the upstream and let me push it again. All right let's go back to the repo and you can find everything. If you go to the branches it should be called project slash search agent. You can see it right over here. And let me now show you here the commit. And let's go check out the main file. And everything you can see it's right over here.