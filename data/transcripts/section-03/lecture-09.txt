Hey there, Ethan here. And I want in this video to dive a bit deeper about the implementation of structured output. So as we saw in the course, structured output allows agents to return data in specific, predictable format. So instead of getting a raw-text answer, we can get a Pydantic object, we can get a JSON response, or a dataclass, and something which is downstreamable to our application so we can use later. Now, we saw how we can use it in the create a agent function, right? Now, there are a bunch of implementations to structured output. So using structured output has two different types of implementation. The first one is tool strategy, which is going to use tool calling under the hood, and the second is called provider strategy. And this is going to be using the native model structured output capabilities. Now, LangChain is going to choose by default to use the provider strategy, unless we specify otherwise. So let's start talking about the provider strategy. So most top-tier models, they offer support for structured output natively. So this means we can use their own APIs and use a structured output argument, and they're going to do all the heavy loading and they're going to make the response be in the format that we want. And we can see that it's going to receive a bunch of schema types. So it can be a Pydantic model, a dataclass, a TypedDict and JSON scheme. We can see it right over here all the examples. This is for a Pydantic model, this is for a dataclass, this is for a TypedDict, and this is for a JOSN scheme. And by default, if the model we're going to be using in the create agent is going to support structured output, then LangChain is going to be using that, because by doing it, they're shifting all of the responsibility to the model provider to return us a good answer. And this basically means that if we get a wrong answer, (laughing) we can talk to the vendor and not LangChain. Now, some models do not offer this structured output API. In case the model and all of the top-tier models supports tool calling, we have a workaround to do it, and this is actually how everything evolved. So we can actually use tool calling and LangChain under the hood uses tool calling with the schema of the object we want in providing one single tool to the LLM and saying to the LLM they always need to choose that tool. And by doing that, we are forcing the LLM to enforce the schema that we send it. So this is a nice workaround to get structured output here. So LangChain now implement this for us. And in this case, it also supports all the Pydantic models, dataclass, TypedDict and JSON scheme.