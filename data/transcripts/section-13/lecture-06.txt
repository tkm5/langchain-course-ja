Hey there. Eden here. And in the next two videos, we're going to be implementing our tool executor node. And this node is going to take as an input the I message, which is going to have the information of the wanted search queries. And it's going to run Tavileh to get us real time results and real time information from the web. Through this video, we'll have all the components for our graph ready and we'll build our graph. So let's go to the code. Alrighty. So let's go and create a new file. And I want to call it tool executor. Let's start by importing low dotenv and load the environment variables. And now I want to import from link chain Tavileh. I want to import the Tavileh search tool and make sure you have Tavileh installed. So you can do that by writing poetry. Add link chain Tavileh. And you want to make sure that you have the API key. So let me go and take that real quick and I'll log in. And let me go and copy one API key and let me put it in my env file. And by the way, don't worry about me exposing my API keys. I revoked them after I finished filming this video. And we want now to import the structured tool class from Link Chain, which is a component that's going to allow us to convert a Python function into a tool that can be used by Llms. So it's going to take that function and provide to the LLM a structured schema for the function, which will help the LLM understand how to use this tool. And then we're going to import the tool node class from Landgraaf. And this is a very cool class that saves us tons of work. And it's a node in the graph that we can invoke. And it's going to look in the state for the messages key. It's going to check the last message, and it's then going to see if there's any tool calls that were decided by the alarm. And if there are, it's going to execute those tools for us. And it can do this even in parallel. So this saves us tons of work. And trust me, before that we would need to do everything ourselves. And I actually did that in the original version of the course. And I'll even leave this implementation as optional in case you want to check out all the heavy lifting that tool node performs for us anyways. So this is going to be the node that is going to execute the tools, and we're going to instantiate it with the tools that it needs to run it. We're going to see it in this video. So it's going to be very clear. Cool. So let me just import the answer question and the revised answer classes. Let's go and initialize our search tool. So we'll start by creating an object of search. So we'll do that with max results equals to five simply to get five results. And it's going to give us back a link chain tool with the function of the search engine. And we don't want to use it as is, like we usually do. We want to do a cool trick here. So we want to take the original tool and its functionality, and we want to create from it two different tools. It's going to be two different tools with the same functionality of the search, but they're going to have different names because they serve different purposes in the application workflow. So we're going to have an answer question tool, which is going to be used during the initial research phase when the agent is first answering the question. And then we want to have this revised answer tool which is used during the revision phase when the agent is improving its answer based on the reflection. So both tools are going to run the search. And that's why we need those objects the answer question object and the revised answer object. Because we want to get their names in order to label those tools. But theoretically we can use one tool, but having separate names in two separate tools allows the system to clearly track which stage of the research process triggered the search initial research versus the revision research. So it's going to help us in debugging and evaluating the response. All right. So let me create a new function. And I'm going to call this function run queries which is going to receive as an input the search queries which is a list of strings. And in its description it's going to have run the generated queries. And let's also add the quarks here in case the LLM is going to fail some other values. So we won't get an error in that case. And the implementation here is going to be very straightforward. We're going to run the Tavileh tool with those queries. So we're going to iterate over them. And we're going to run the query with the batch function which is going to run them concurrently. All right. So now we want to create from this function we want to create two different tools with different names. So one tool is going to be answer a question and the other tool is going to be revised answer. And they're both going to run the search the run queries function. And the structured tool class is going to help us achieve that. And they're all going to run in the tool mode. So the tool mode is going to run two different tools. And one tool is going to be the search tool that originated from the first creation of the research. And the other tool is going to be a search query that originated from the reflection revision. And that's the cool trick over here. So let's go and do that. Let's go create an object of tool node. And in order to do that we'll need to supply the list of tools that it's going to run. So let's create the first tool. So we'll take the structured tool class. And it's going to have a method from function which is going to receive a function and convert it into a tool with schema and description and all of that that we saw before. And another argument is going to be the name of the tool. So here the name is going to be the name of the class. And we want to do another tool which is going to run the same function. But it's going to have a different name of the revised answer class. And that's it. We are done. Here we have all the moving parts in order to create the graph. Now I remind you this tool is going to examine the state. It's going to check the last message. And if there is a tool call it's going to execute the relevant tool call. All right let me run some formatting over here and let me go and add everything we did right now. And let's commit it. So I'm going to commit this to the branch of slash projects slash reflection agent. And if you want to see the code you can select in the repo a branch of project slash reflection agent. And you can check out the commit here, which has all the code that we did in this video. And it's going to be linked in the videos resources.