Hey there Ethan here. And in this section we're going to build something which is called a reflection agent. It's going to extend our previous example of the reflection agent, but it's going to incorporate tools, for example, a search tool which is going to search online for real time data to enrich our answer. And we're going to review some advanced prompt engineering techniques in order for our reflection agent to be able to digest the feedback correctly and to really address and improve through the iterations, because to create a critique, it's not that hard, but to really leverage the LLM to incorporate that critique and to improve over time is something which is challenging. And for that, we're going to show you some very cool tricks that will help us do so. Now, where does this architecture come from? It comes from a paper which is called reflection, which is a joint paper from northeastern, MIT and Princeton. So the idea for this actually came from a lecture blog that their team created covering reflection agents and specifically covering the reflection paper. Implementing everything with Landgraaf. Now, I have to say that the link chain team and specifically Lance from Link Chain, they did an amazing work. However, their implementation is actually for me, it was a bit hard to understand, so it really took me a long time to understand what was going on. So what I did is take it and refactor it a bit in order to make it something which is much more easier to explain and easier to digest, because the implementation was quite hard to understand. And of course I'll be sharing the link in the video's resources section. The goal of the reflection agent is to give us a very detailed article about a topic that will give it, and we want the article to dynamically fetch relevant information from the web. And we want to have citations for the reference data. And of course we want to incorporate a quality right critique loop. We basically want to get a very high quality answer. And this is an example question right, about AI powered SoC, autonomous SoC problem domain startups that do that and raised capital. So I'm not sure if you're familiar, but AI powered SoC or Hyperautomation autonomous SoC like companies like talk is something which is exploding right now, and it's getting a lot of attention. And the idea here is to take the security operations center and to leverage AI agents in order to start resolving tier one tickets and security incidents. So those kind of tickets don't require a lot of reasoning, and they can leverage external tools in order to triage them and to resolve them, and freeing up a lot of work for SOC analysts already. This is an example response we got from the reflection agent. And we're going now to discuss the architecture of that agent. So the architecture looks very similar to our reflection agent we saw in the previous section. You can see when we start the agent flow, then we first have a responder node which is going to respond. The initial response. You can see it right over here. However it's not only generates the original response, but it also adds a critique to the response itself and a search term. So in the search term, the agent is going to come up with ideal search queries that would be beneficial to get a better response. It's going to help us ground the output that we gave with current events and external data that is available online. So after we have the search queries, we're going to execute the execute tools node, which is going to take our search queries. And simply going to use a search engine to retrieve us results in real time. So I'm going to be using Tavileh, which is an amazing third party. That is a search engine which is highly optimized for LM applications, and we can easily downstream the responses that we get to the LM. And now we're going to downstream the results, and we're going to go to the Revisor node. And the Revisor node is going to take the initial response, which has already an initial critique, and the results of the search engine execution. So it has also external data. It is very relevant to the topic that we're executing. It's going to revisit and change our original response. Now it's going to do that while incorporating the new data and the critique. So it's going to address the suggestion that we got in the previous step to articulate a better answer. But not only that, the Revisor is also going to supply us a new critique to the new revision of the article, and it's going to provide us new search terms that we want to now look up, according to the revised articles that are going to be beneficial, and it's going to give us The citations of the first search that we had. And after that we're going to continue and search for the new queries. We're going to downstream the new information alongside with the critique, and we're going to revise it again. So this loop is going to keep happening until we hit a stopping condition. And after that we finished. And this architecture is very similar to our reflection agent architecture that we saw in the previous section. But we added here a search engine. Let's discuss what we're going to use. We're going to use GPT four turbo because we need a strong enough model to write the text and to write the critique, which have a good reasoning power. Also be leveraging function calling, which is going to be super important in this implementation. And we're going to be using Tavileh as our search engine. And of course, we're going to be using Lindsmith for tracing, because in this complex architecture we want to be able to trace easily.