Hey there. Eden here. And this is a setup video for our boilerplate skeleton for our project. So we're going to implement now the MCP link chain adapters. And we're going to learn a bunch on MCP clients. So in this video we'll create a new project with UV. We'll create a virtual environment and we'll install our dependencies there. And then I'm going to commit it to GitHub. If you want to start from after I'm committing here this code and have the exact code that I have, then you can simply go and run those commands over here. So this is going to clone the repository of the course. It's going to clone the project slash LinkedIn MCP adapters branch. And after we do that we want to go and CD into the Linkchain MCP adapters where all the code here. And then we want to check out a commit that I used here. So this commit has all the code in this video. And don't worry about copying this command. You can download the exact command. I'm going to link it in the video resources. So this is in case you do not want to start from zero like I'm doing. All right. So I'm going to start and go to my GitHub projects and let me clone the repository of the MCP crash course. And the URL is going to be listed in the videos resource. So don't worry about it. All right. So I cloned the repository and let's CD into this repo. And currently I'm on the main branch. And let me show you it. And we want to create now a new branch which is going to be for this project. So let me go write git checkout and I want to write dash dash orphan to make it detached from my original repo. And let's call it project slash link chain MCP adapters. We created the branch and we're on the new branch right now. Let me show you now the current working directory of the project. And now it's time to see what files do we have here. So we see we have a bunch of files. And you're probably going to see the repo where it's much more organized. So don't worry about the files here. What we want to do is to remove those files and start from a clean slate. So let me go and do that. So let me write here git rm rf dot. So this is going to remove all of those files not to track them. And right now we don't have anything. And I listed all the files and I don't see anything here. So this is our starting point. We have a new branch and we don't have any files here. Alrighty. So let's go and initialize our project with UV. So I wrote uv init, and we have now a bunch of boilerplate files that we can work with. We can see that the files that were created is a empty readme main.py and a pyproject.toml file. Cool. So now I want to open the cursor IDE and this is now our working station. So let's go and open up terminal. Let's now create a virtual environment. I'll write UV Venv. And now we have a new virtual environment. You can see we have a venv here. And let me now source it and activate it. So I'm going to copy here the script. And now you can see on the left side we have MCP Crash Course inside parentheses. So this is our virtual environment. And by the way if I'm going to exit cursor and open it again then it should automatically activate the virtual environment. You can see here on the left side. And if not you can simply activate it like before. Anyways, let's go now and let's install our dependencies. And if I will go to the link Chain adapters repository. And we can see here in their example we need a bunch of packages. We need the link chain MCP adapters package lang graph package and link chain OpenAI. And notice we are not installing explicitly the MCP package because when we install the Lang chain MCP adapters package, it installs it automatically. Alrighty. So let's go and let's copy now those packages and let's add them with UV. And after we install them let me also add python dot env package to load up environment variables. And and if it's not already installed as part of their dependencies. So let me go and add python dotenv and we can see it's already installed. And let's see the toml file. And we can see now those are the dependencies that our project needs. And if we go and head up to UV dot log file here we have the exact version of all the packages in our virtual environment that we need for the project. And for example, here I installed LinkedIn core. Right now the current version is 0.3.5. One of LinkedIn core. And when you install it you might have different versions, probably newer ones. And I'm going to keep this repository and videos up to date. So unless there are breaking changes I'm going to leave it that if they are I will update this video. Alright, so let's go to our main.py file and let's go and try to run it. Let's see, just as a sanity check that everything is working and I'll run it with you've run Main.py and notice we're inside the virtual environment. So it's going to contain all of our packages. All right. So let's go and run it. And boom we get the output that we want. What a beautiful program. Alrighty. So I want to make it async. So I turn this function into a coroutine with the async keyword. And now in order to run our main file I need to run it with async IO run. And I love these cursor autocomplete. I'm simply pressing tab tab tab and it completes me. And I forgot to import async IO. So let's do that. And let's go now and run the code again. And we can see it's still working. And this is a good sign. And I want to create now a dot env file to hold our environment variables. Because we're going to be using an LM. So I'm going to use a managed LM. And let me paste here the values of my environment variables. And by the way don't worry about the values here of me exposing them. Um I'm going to revoke it right after I finish exporting this video. Anyways, I'm using OpenAI right now, but you can use any LM you want that supports function calling. So you can use anthropic sonnet. You can use Gemini. By the way Gemini has a free tier. So you can use it as well. And you can use deep sea or any other LM which supports function calling. So the first environment variable is going to be our OpenAI API key or our API key? Now the other four API keys you can see here of linked chain. They are for the link Smith tracing. So we can actually trace the LLM calls and see exactly what's being sent to the LLM. And what do we get back. So I think it's very important to understand it's not a must for you. So if you do not trace it you simply need to put the link chain tracing V2 equals to false here and it should work. And if you are using simply go to the link chain platform and generate the API key. From there. Let me know if you wanted to make a video on that, but I'm assuming that you know how to do it anyways. So I put my API key, I put the endpoint and I call the link chain project MCP test here. So even though I did revoke now the API keys so you can't actually use them, I want to add here another file, let's call it. Gitignore. And I want to not commit the file to the repository. So let me just write here And this is simply going to ignore the dot env file. And you can see it's also grayed out here. So git is not going to track this file. And I'm not going to accidentally upload it to my repository. All right. So let's go back to the main.py file. And now we want to load those environment variables and to see that everything is working correctly. So we can continue. And to write our actual code and write our first MCP client. So I'm going to import from env the load inv function. And I'm going to call it right before my code runs. And as a sanity check let's go and print the OpenAI API key just to see that we actually loaded it into our environment variable. And let's go and try to run it. And we can see we forgot to import the OS module. So let's do that and rerun it. And boom we can see now our API key and our environment is indeed loaded with the correct values. So that's pretty much it for this video. We have all the boilerplate code. And from now on we can go and we can implement our MCP client. So let me simply go and add everything and let me go and commit it into our repository. So now we are tracking all the files we created. And let me show you one of my favorite cursor features where you simply go and generate automatically with AI the commit message. And let me go and commit this code here. And now let me go and push it into the repository. Oops. I need to set my upstream repo here. And now we should see the code available on GitHub. So let's go to GitHub. And if I'm going to select now the branch of project slash MCP adapters. And let's go and click that. We can see now all the code that we just wrote. We can see the main.py file, the UV log, the pyproject.toml file and everything.