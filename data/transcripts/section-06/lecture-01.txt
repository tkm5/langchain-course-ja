Hey there. Eden here. Hope you're enjoying the course. And in this section we're going to be diving deep into function calling, aka as tool calling. We're going to be using those terms interchangeably. And by now you should be familiar with the react prompt. And we saw how cool this prompt was. And this entire loop of reasoning and acting and how we can build with it some very advanced tech. However, the react prompt, you probably notice it's not that reliable, and it's enough that the LM is going to generate one wrong token and it can mess up our entire response, because link chain is going to parse it with regular expressions. While this prompt is the basis for a genetic behavior and AI agents. It's really not that reliable. And the natural evolution of this prompt and the natural evolution of this prompt into a production grade reliable solution, is the capability of Llms to do function calling or tool calling. And this is what we're going to be covering in this section. So function calling the really really gist of it is that instead of relying on this react prompt, we're actually going to be relying on the model provider, the provider. We're going to be relying on anthropic, on Google, on OpenAI, and the model is going to output us in a very special place in the response, the function call, which is going to be a beautiful JSON with the function name, the function argument, and we or link chain can simply take this JSON can parse it very, very easily without using any regular expressions because it's JSON. So we can simply access its fields, and then we can continue with our algorithm of our AI agent. And the results we're going to get with function calling are going to be much more reliable than using this react prompt. And this is what we're going to be demoing. This is what we're going to be showing in this section. And actually these days the best practice is to use function calling when building AI agents.