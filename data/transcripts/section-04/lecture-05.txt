Alrighty, let's go now and let's run everything. And I want now to show you the logs, the outputs, and we'll have a better understanding of how everything here is working together and what we just did. Let me just go and click um continue here. All right. We can see now we're entering a new agent executor chain. And right now the prompt we wrote plugged in with all the tool descriptions of the search is all being bundled up with the prompt. And that's being sent to the LM. All right. And now the LM is going to return us an answer. And this we can see in green here. And the LM returned to find the job posting I will use the search tool. This is the tool name inputting a specific query to look for an AI engineer position involving link chain, blah blah blah blah. And then we have here action which is going to be search which is going to be the tool name. And then we have here the action input which is going to be the string of AI engineer LinkedIn job description. Bay Area LinkedIn. All right. So this right here is what the LLM returned. Now it returned us this kind of answer with this specific format of action and action input just because of the react prompt. And I will be elaborating on this in the rest of this course. But this is this kind of hack here, right. So the LLM is going to always respond this with these kinds of format where we have action, which is going to have the tool name and action input, which is going to be the input for the tool name. Now LinkedIn and this is the beautiful thing LinkedIn is going to take this for us. It's going to parse out those strings. And it's going to figure out that it has in its disposal the search. And it's going to invoke the function of the search, which we imported from the LinkedIn integration. And it's going to invoke this function with this input. And LinkedIn is going to do all this parsing and all this heavy lifting for. 54. And I remind you, we had this output parser from before in the Create react agent. So that's part of the chain is going to do that for us right. So it's going to take this answer and it's going to extract from it the name of the tool that we need and the input for that tool. Right. So now link chain is going to execute the search tool. So this is what's going to happen. And it's going to get a result. And this is what we're seeing right now. And here we have the result of the tool execution. So link chain ran the tool and it got us the result. And in this result here we can see we have the query which is the same query from the action input. And then we have here the results. So here we have a list of URLs and the description of the search results. Just like we saw in the playground here. Right. So we have here now the tool result. And the tool result is often referred to as an observation. And the LinkedIn component that was responsible of running and executing this tool call was the agent executor. So now the agent executor is going to take this observation, the result of the tool, and it's going to run the same reasoning chain from before. However, now it's going to attach the observation. So the result of the tool call. So now the LLM is going to have the original question. And it's going to have in its history that it's invoked the search tool with the search result. And now it's going to come up with the answer. Right. So this is what's going to happen here. And this is why we need the scratchpad. The scratchpad from the prompt template before. This is going to hold all of this history right. All of the tools that were selected and the tool result. And now the LLM has all the information it needs. And in this iteration it can actually return us the answer. And now we can see here in the green the answer of the LLM. And here we can see it has. Final answer. And now the final answer of the LM. And the agent finished running. And it provided us with three job posting for an AI engineer using LinkedIn. And at the end, LinkedIn is going to return us an object, which is a dictionary which has the key of input and has the key of output. So the input is going to be our original query and the output is going to be the final LLM response. All right. Let's now go and review the trace. So let me open up my browser and let me go to the Linux platform. And here I have the project link Smith project which I defined which is called search agent. And let's check out what we have here. So we can see here an agent executor run. Here we can see our input. Here we can see the output. And we can see we got here an answer. Let me go and click this URL here. Let me show you that this is a LinkedIn job posting. So we can see Um. Yeah, this is a job posting. Let's check out this one. Yeah. This is also a job posting for an AI engineer. And let me go and click on this one. Yeah. And this one also. And here you can see even LinkedIn in the title. All right let's go back to the traces. And let's try to break it down step by step. And this is the prompt template. So we can see this is the input for the prompt template. And the output is this text right over here. Now you can see that this is the prompt populated with all the details about our tools which are the search. So we have here the tool names and the tool descriptions. And this is what eventually is going to be passed to the LLM. And we can see here instead of the placeholder, we have the question that we gave as an input when we ran the agent. All right. And this is the LLM call. So we can see now here we simply sent that to the LM. And here we can see now the LM response. And after we get the LM response. And this is the part I didn't dive into, the engine is going to parse it. So it's going to take from this raw text here. And it's going to extract the tool name and the tool input that we need. And we can see here that the type is agent action. So this is the action that the agent needs to do. We have here log. So this is sort of the justification of why the agent did what it did. And everything here is very organized. And don't worry about this. In the next section we'll be diving deep into all of this and how this is working. All right. So then the agent executor ran the tool. So here we can see that this is the tool input. And here we get the tool output. So this is what we have here. And then we have another iteration of the reasoning. So this is now the second prompt which is sent to the LM which is kind of like the original one. But it also has the information about the tool call that we made and what is the tool result. And then the agent is going to sorry, the LM is going to respond with an answer that we can see right over here at the bottom here. And yeah, that's pretty much it. Link chain is going to go take it going to parse it going to do it very very nicely. And then it's going to output us the response here. Let me just go and commit this code now to the repository. So let's create a new commit. Sorry. Let's create the commit. And let me call it react search agent. And let me go and push it. Sorry. Let's go and fix that. I have a bit of configuration issue. Don't worry about it. And if you want to check out the exact code I was using, go to the branch project slash react agents go here to the commit list. And here is the commit I just pushed. Let me go and minimize this. And here you can see the exact code that I was using with everything I just showed you in the previous videos. Hey there Eden here popping up. And that was a lot. So we created and ran our first link chain agent. Now it was comprised of the reasoning part and the execution part. And we saw it all boils down to a very special react prompt. The entire goal of this section is simply to get you familiar with the interface. It's okay that you're not understanding every moving part here under the hood. This is what we're going to do in the next section. We're going to break this down one layer deeper, and we're going to understand all the chain components that are running together here. And then we'll truly appreciate all the heavy lifting. Link chain is doing for us. And the cool thing that we can see here is that the reasoning engine, it all boils down into a prompt we send to the LM. I mean, how cool is that? And this is the basis for all the genetic technology we're seeing right now, this is the core primitive. This is what was started. All right. So the answer we got from our agent is text. While text is nice, we can't really use it in software. What we really want to do is to get structured output. We want to get this kind of output into a Python object. We can go and we can maybe serialize, we can pass downstream to another application and something we can work with programmatically. So in the next couple videos we're going to introduce the idea of output parsers which are going to take the LLM response. And they're going to structure it as JSON objects as Pydantic objects. And they're going to help us use programmatically the output of agents. And this is very important when building robust software. Now I'm going to give you a quick hint. The answer to that is going to be a prompt as well. So everything boils down to a prompt. This is beautiful here. Anyways, let's go to the code.