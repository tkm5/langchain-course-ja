All right. So we have the tool. And now we need to configure an LM. So let's go and do that. So let me initialize a chat open AI. And I'm going to give it GPT four. There's a reason why I'm using GPT four and not GPT five. And I'm going to reveal this reason in the end of this section. And now let's go and use the link chain hub to pull something, which is called a react prompt. Now before we run this, just a quick note here. In case you're using the EU endpoint for meat, you might encounter this error where it says that it cannot find this prompt. And the reason you're getting this, because the public prompt or the public prompts are hosted in the US instance of Lenox-smith, which is the default public hub instance. And if you're using the EU instance, then it does not automatically mirror all the public prompts from the US hub. So in case you're getting this, we have two options. Either you remove the environment variable of length underscore endpoint, or you can simply go and copy paste this prompt template and create a prompt template object. And let me run it in debug. And let me show you this react prompt. So this react prompt over here is going to be a prompt template. But it's going to be a very special prompt template. Those are going to be its input variables. It's going to receive an input which is going to be the user's question. It's going to receive tools and tool names. And those are all things that length chain is going to extract from the tool object that we built earlier. And it's going to have also the agent scratchpad, but ignore it for now. In the next section we'll be elaborating on this agent scratchpad here okay. So this is the variables that it's going to receive. Now let me show you the template that it's using. Right. So we can have an idea what's going to be sent to the LM. So the template here is. Answer the following question as best as you can, and let me open it in the prompt tab so we can review it in a much nicer UI. Okay so this is the actual prompt template. Now you can see here it's going to receive tools. The tool names. And then we have here the question is going to be the input. And we have here thought Agent Scratchpad. Okay. So in this react prompt we have this middle part over here. And this is actually what's going to be the magic. And it's going to be the secret sauce of our reasoning. And this is how it all started. Okay. It's simply everything is a prompt with LLM. And it really amazes me to really think about that. This is the basis for all of this modern technology that we have today, like cursor, Cloud Code, Devin, and all of those deep agents. And I'm not going to elaborate on this prompt for that. I have a dedicated video to discuss why did it came from, why it's useful. And this is called the react prompt. It originated from react paper. And this is really the basis for everything. But for this section all we need to know is that this prompt works. And for some reason everything would work with this prompt. Okay, so this is what we need to have in mind. We're not going to elaborate on this video. I highly suggest you check this theoretical part in case you want to dive deeper into this. All right. So now we want to go and we want to create our reasoning engine. All right. So for that we'll use the create react agent function which is going to receive the LM. It's going to receive the tools and it's going to receive this react prompt. Now this is going to create for us a chain. And this is going to be our reasoning chain. You can see that it's going to return a runnable. So this is an equivalent for a chain. And it's going to plug all of the values of of the tools, and the input that the user will provide is going to provide everything to that prompt. Now, hopefully when we're going to run this chain, then the model, the LM is going to reason on the input and it's going to say, hey, you need now to run the search with the following query. All right. So this is hopefully what this chain is going to return us. All right. So this is the reasoning engine right now. So we get that part really set up here we have the reasoning engine. And now we need the execution of the tools here. All right. So it's going to be here this agent executor that we imported from before. Now it's going to receive the chain from before. By the way I called it agent. This is not really an agent. It's going to be a simple chain. It's going to receive the tools. And I also added here verbose equals to true. So we'll be able to see when we run it. We'll be able to see the reasoning process. And we'll be able to see more logs here. All right. So this is going to be our agent. Runtime. I remind you, don't worry about the internal implementation. We're going to see this and we're going to implement everything from zero in the next section okay. So you know exactly how this thing is working right now. But what this is going to do, it's going to run in a while loop. And it's going to run this react chain over and over again. And every time there needs to be a tool call, it's going to call that tool, and it's going to feed the output of the tool back to the LM, and it's going to do this until it finishes the task here. All right. So this is basically what it's going to do. And don't worry about the arguments that it will receive. We're going to cover it in the next section when we'll implement everything here from zero. So I promise you you'll know exactly how this is working. Let me just show you a quick peek of the implementation of link chain. So this is the Create React agent here. And you can see what it's going to return. Here is a runnable object where it's going to take the prompt the react prompt. And it's simply going to send it to them. It has this output parsing which I'm going to discuss later. So please, please, please don't worry about this output parsing. Okay, I remind you what we're interested here is how to use the link chain interface. In the next section we're going to see exactly how it's implemented because we're going to be implementing it from zero. All right. So just to summarize what we saw so far, we defined our reasoning engine, which is going to come from the create react agent function which is going to return us with a chain which is simply going to receive the tools, or it's going to receive the user's query, and it's going to send everything to the LLM. Once we have that, the LLM is going to return us a response and the agent executor is going to be responsible to maybe call a tool or to run another LLM call. And it's going to be the orchestrator of this prompt over here. All right. So we are about to finish now the code. And let's now go and let's invoke our agent. So let me just create a new variable. And I'm going to call it chain, and I'm going to make it equal to the agent executor here. Now, I know this looks funny here, but this is actually preparation for something that we're going to be doing next. And now let's go and invoke this chain. All right. So I'm going to paste here this snippet. And here we have a variable called result which is going to be our chain when we invoke it. And here we're going to provide the invoke method the keyword argument of input. And it's going to be a dictionary. Now this dictionary is going to have the key of input. And this input right over here is going to be what's actually going to be populated in the prompt template that we defined above. And the query is going to be search for three job postings for an AI engineer using link chain in the Bay area on LinkedIn and list their details. And in the next video we're going to run, debug and examine the output. So hopefully it will be clearer then.