So I'm in the newest LinkedIn documentation on agents. And we have here a button which is going to allow us to copy this documentation as text. And this is actually something super innovative and something very useful that the team did, because it's going to allow us to use all these documentation as context. We'll be sending to our AI powered code editor like Cursor or Cloud Code, which is going to help us figure out how to do things with the new docs. This is a very interesting topic, which is called lm dot txt, which I do actually cover later in this course. You can check out those videos. They are under the MCP section right. So now I want to go and migrate my code to be using link chain v1 to be using the new interface. So this is going to be actually very easy. And the way I'm going to do it is actually with cursor. Now I'm doing it not because I'm lazy, it's because you can really see the difference with the generated diff cursor is going to create for us so we can really see everything side by side. What is being removed? What is being added? This is actually easier to understand in my opinion. So let me just fire up cursor agent and let me prompt it something like migrate the code in Main.py to the newest create agent interface. And here is the docs. And here I'm simply pasting everything from the docs. All right. So I'm going to fast forward everything because this query may take a minute or two. And let me go and wait until we get here. The diff. All right. So this query took us around three minutes. And let's review the diff. And it's actually going to match what we saw in the documentation in the earlier video. So we do not need the prompt hub because we do not need the react prompt. We do not need the agent executor because this is all going to be abstracted. And this is all going to be running on a graph under the hood. We do not need the create react agent we imported instead the create agent function. We don't need prompt template because we're not writing a custom react prompt, and we do not need a runnable lambda because we're going to be using a built in argument, which is going to help us accept structured output. And you can see we do not need this special react prompt with format distractions, simply because we are not going to be using a react prompt, because the reasoning is going to happen through the function calling capabilities of LMS. Alrighty. So after we finished with the imports, let's go and discuss the implementation and we can see we still need the agent response schema and we still need the list of tools. These haven't changed, but we did remove a lot of code that is around the structured output and is around the react prompt, which we do not need. And we simply have here a model variable which is going to be an instance of chat. OpenAI with GPT four. Maybe we can edit it later for GPT five. All right. And let's check out the implementation itself, so we do not use any more the create react agent function. Instead, we are using the create agent which is going to receive an input the model that tools like we did before. And this time we're also going to provide it with a response format argument, which is going to be, um, the schema of the agent response, which we covered in earlier videos. So that's going to make sure that the answer that the agent is going to return us is going to be a pydantic object of agent response type. And we can see we do not need the agent executor so that while loop, we do not need it anymore, we do not need the extract output lambda. We do not need the chain to extract the output link chain is going to handle everything for us. Now. It's super important to note that I will be showing in this course how this is implemented. Within Lang graph. We will actually build everything from zero and you'll know exactly what's the magic over here. So right now we're just reviewing the interface. So let's show how to use it and how to invoke it, because there is one small difference. So now the input we're going to be sending is simply a list of messages. So it's going to have the role of the user. And it's going to have the same content as we had in our input key. And the reason why we do it. So why we send messages instead of sending in the key of input. This is something I'm going to leave open right now. But I promise you, we do answer in this course. Why this subtle change which actually encompasses within it a lot of depth in it. So I don't want to give any spoilers. We will be seeing it later. And lastly, in order to access the answer of the agent, which is going to be the structured response as we want it to be, we need to access the key of structured response within the result here after we invoke the agent here. Um, so this is simply how long chain is going to structure the answer. Okay. So this is it. Those are all the changes. And you can see it's actually much simpler now to use the create agent. And the interface got way more simpler. And there is actually a reason why I did not start immediately with this implementation, and simply because I want to show you the evolution for you to really appreciate and for you to understand the motivation and the architecture decision that the link chain team and the link chain framework made in order for it to be where it is today. And in order to see why this create agent function, why it has much more benefits over earlier versions of the create react agent or create tool calling agents. And it's going to give us a much more in-depth understanding of the ecosystem and agents in general. Okay, so I just remind you that up until now we only saw interface. So we haven't discussed what link chain react is doing under the hood. And even what is this function is doing under the hood and how it's working. And this is going to be happening right in the next couple of sections.