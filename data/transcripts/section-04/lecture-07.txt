Remember in the previous videos when I wanted to call the agent executor, I wanted to call it the chain and I will say it would be clearer later. So now is the time we're going to shed some light on this. So theoretically we can simply take the result and we'll extract the output key in that result. Dictionary reminder. It also has an input key. And we can take that string. And we can use the output parser parse method in order to turn it into a Pydantic object. And this is pretty much what we did in debugging. However, that is not really pythonic and we actually can use the LCL, the link chain expression language to get the same result, but more elegantly. And for that we'll be using the runnable lambda. Now, the runnable lambda in the Chain expression language is a lightweight wrapper that turns any Python function, usually a lambda function or simply callable function, into a runnable, an object that implements the link chains. Runnable interface. So this interface standard arises how components like chains, like models, are invoked in batched and streamed in link chain. So the runnable lambda is going to allow us to easily integrate custom logic or simple transformations. And basically it's going to give us the invoke interface. So it's going to turn everything to be invocable. And let me bring everything down to earth with the first example. So I want to implement the extract output variable, which is going to be a runnable because the runnable lambda class implements the runnable interface. And here we have the transformation here it's a very simple transformation. So it's going to be this lambda function over here where it's going to take the input and it's going to extract from that input which is referred to as x. It's going to take x at the output key okay. so if the input is going to be a dictionary, it's going to look up for the output key. And then this is going to be what the invoke method is going to return us here. Now this is going to be piped right after we execute the agent executor with our input. So this is going to take the agent executors output. And it's going to extract the output key of it. Yeah I know the the wording here um was double wording but this is what it's going to do. And now we want to parse it with the output parser. So I'll create another runnable lambda which is called parse output. And the implementation of it is going to be a function, a lambda function that is going to use the output parser.parse function on the input it gets. And the input this runnable is going to get is going to be the output of the extract output runnable okay. So if we're going to pipe everything together and compose everything together with the agent executor. With the pipe operator. Then first we are going to give the input is going to be passed to the agent executor. And when we invoke it, it's going to run the react agent. It's going to use the given tools and it's going to output a the response of the agent. So the output is going to be a dictionary. Now this dictionary is going to be passed to the extract output runnable which is going to extract the output field. And then the extracted string is going to be passed to the parse output which is going to parse it into the structured Pydantic model. So at the end when we're going to do chain dot invoke the, it's going to be running the compose chain on the input query, and it's going to return us a parsed structured response. Now I know it's a lot to digest. And trust me, I swear for me to learn how to use an expression language took me forever. So I want you to take a deep breath, and hopefully it will be clearer when we're going to review the traces in Lamb-smith very, very soon. Okay. So let's first run all this and let's see what we get. Let's go now and fast forward everything. And we can see we hit the breakpoint. And here we can see now the result is of type agent response here. And this is our pedantic object. And we can see the answer attribute with the answer. And we also have now the sources attribute which is going to be a list of pedantic source objects. So this is the structured output. And from here you know we can serialize it. We can do a lot of cool things here. All right. Let me show you now the trace. And in the trace you can see now the two runnable lambdas we saw from before. And let's see an example of the first one. And this is going to be the extract output runnable lambda. And here we can see that the input when we invoke this runnable is going to be what the agent executor outputted us. So it's going to be a dictionary with the input key and the output key. And the output of this runnable is going to be the content of the output key here. So it's going to be the JSON string of our object that we want to parse now. And this JSON string this is what we're going to be propagating to the output parsing lambda. So let's go here. And here we can see now that the input for this runnable is going to be the JSON string. And the output is going to be the Pydantic class. So it's going to have the answer and it's going to have the sources attributes and the overall chain. Let me now show you the overall chain is going to get the inputs and it's going to output us this pedantic object. So this was done with the link chain expression language. All right. Now I remind you that I still owe you an explanation why I did not use GPT five. Here, you see, I'm using GPT four here and not GPT five, even though it's the latest and greatest here. Now, the reason for it. Let me just show you what's going to happen if I'm going to be using GPT five. So let's go and let's go and switch it. Let me now run everything. And you can see now I get an error here. Now this is a 400 code error with unsupported parameter. Stop is not supported for this model. All right. And it's not that GPT five is a bad model. It's actually the most advanced and most capable. The reason is that this model does not support the stop argument. And in the next section, we'll be elaborating on this stop argument in the react algorithm. And why do we need it? But in fact, if we're going to be using the tool calling agent, which is going to be leveraging function calling, it should work just as fine and will be elaborating all of that in the course about function calling, about tool calling. And this is the next evolution of the agents. But what we just witnessed here, what we just saw here, this is the basic for everything. If you understand that, you will understand everything. All right let's finish it up. Let me go in format everything and let me add and commit everything here. So those are all the files that changed. And let me go and commit it. So I'll call the message here added output parsing. And let me push that. Now if you want to get the code you can simply go to the branch project slash search agent. And you can check out the commits there. And yeah, you can compare the code and even clone it and use it.