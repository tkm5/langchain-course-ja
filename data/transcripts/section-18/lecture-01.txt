Hey there, Aiden here, and I want to show you something super useful when developing agents in the LangChain ecosystem. With LangChain, or with LangGraph, and using LangSmith. And if you've been coding recently, you are probably been using now a AI coding editor, like Cursor, like Claude Code, let me open Claude Code. You've been using those coding editors to write your code. I've been using them a lot. Now, with those coding editors, while they're awesome, they have a very annoying problem when it comes to ever-changing frameworks like LangChain. So, LangChain is very dynamic, it is continuously changing. And trust me, I know it, I'm updating the course continuously, it's very, very hard to keep up with the rate things change. Sometimes API break, sometimes objects are deprecated, and it's really hard to keep up with it. Now, LLMs, they don't keep up with it, because LLMs are trained in a given point of time, and they're trained on the LangChain version which is out by the time that the training data was collected. And we can use an LLM that was trained a couple of months ago, and the LangChain ecosystem can change dramatically. Now, this is true not only for LangChain, but for almost everything in this field, in this AI field, this is continuously changing. So if we're going to be using those coding agents for something very dynamic, like LangChain for example, if we're going to ask, "Write me an agent with LangChain that does X...", depending when we're going to be running this, we might get some rubbish answer, which is not going to be helpful, which is going to be based on old variations of LangChain, which is not going to be up to date. And the LangChain team are pretty aware of this. And if you go to their documentation, right over here, you can see, you have here this Copy page. So, first, with one click, you can go and copy this entire page, and you can put it in an LLM in a chat application and can use it. Now, if you go here and click this, you can see you can also ask to Copy MCP Server. Now, if I'm going to copy the MCP server, let's say with Cursor, let me open up Cursor here, what this is going to do, it's going to add the LangChain docs as an MCP server. You can see here, this is a streamable HTTP server, which is going to be pointing to the LangChain Docs MCP. So, LangChain was kind enough to create a public MCP server, which we can go and query without any API key, without anything, and simply take their latest and greatest documentation. And to use it, we need to simply install it. So, now this is installed. You can see it has one tool in it, SearchDocsByLangChain, "Search across the docs of LangChain knowledge base to find relevant information, code examples, API references, and guides. Use this tool when you need to answer questions about Docs By LangChain, find specific documentation, understand how features work, or locate implementation details. The search returns contextual content with titles and direct links to the documentation page." And it receives a query. So, and now let me go and disable for a minute context7, because context7 is going to do this for many, many libraries. The difference here is that DocsByLangChain is specifically tailor-made to LangChain and the LangChain ecosystem, and context7 is much more general. So if I'm going to be using a coding editor to write LangChain code, I would like to use this MCP server. So if I'm going to go now to the agent, and let me ask something like, "Hey, can you please tell me, how do I write a LangChain agent according to the latest docs?" Let me go and click Enter. And now the AI agent is supposed to invoke the LangChain MCP server. So now we can see it's running the SearchDocsByLangChain, it's refactored my question, latest LangChain Python agent creation. And now LangChain officially returned the relevant context, and we get the answer, which is to use the create_agent function. And let me go now and disable tavily MCP, which has search tool, extract, crawl tool, I want to disable it for this example. And let me now create now a new chat here. Let me copy the same prompt, and let me paste it. So now I don't have any MCPs connected, and let's see what's the answer of the LLM going to be now. So now we can see it's invoking a default search tool by Cursor. So it's going to be using Cursor's different search tool. And here we can see, initialized agent was actually found. And this is the first agent that was created, it's been deprecated for a very long time ago. Trust me, I refilled this video about it a bunch of times, and we can see it's still going, it's still searching things, it's still acting, and we can see it taking a lot of time. And this is because we are not using the LangChain MCP server. And let's see what result we have here. Here we can see, we have create_react_agent, which was actually deprecated. And we got here deprecated code. So if we didn't have the LangChain MCP server, let me go and enable it, so if we didn't have the LangChain MCP server, then the code we got Cursor to write is going to be the wrong code, and the deprecated code. So the fact that LangChain went and implemented a remote MCP server, which is going to make our lives way easier when using coding agents, is something very impressive, I have to say. Now, LangChain were actually one of the first companies to also make their entire documentation websites with llms.txt, which we covered in the course. And we can see we have other integrations, we can use VS Code MCP, we can use Claude for that, and this is very, very useful. So, if you're going to be running some LangChain code, I highly recommend you using this MCP server. And I want to show you something even cooler. If you go to chat.langchain.com, you can ask and talk to LangChain's documentation helper, which they created. And let's paste the prompt from before. "Hi, can you please tell me how do I write LangChain agent according to latest docs?" And what's actually going to happen, the tool that is going to be invoked to search the documents, searching the documentation for agents, I think it's actually going to be using the same MCP server we are using. I'm not sure, I need to find it out, but this is probably the case. And here we can see, we got the correct answer, with the create_agent text. And you know what, let me verify it, let's go to view trace here, they've done everything so it'll be super easy and super transparent to see what's happening. This is very, very crazy. Yeah, you can see here, we are using the SearchDocsByLangChain. So this is going to be the same MCP server which is going to power the Chat LangChain, official Chat LangChain. So this is very, very cool. And here you can see, by the way, the entire trace for the Chat LangChain run we had. And we can see we invoked the tool here twice. And, first time, it looked for agents. The second time, it went for OSS troubleshooting. And here we can see, it searched for create_agent. So, there were a bunch of tool calls here. So this is something which is really, really wonderful to see, how everything connects together, MCP, LangChain, coding agents, and this is really cool in my opinion. So, just to finish, the gist of it, please, I urge you, if you're going to use coding agents, please go here and use the LangChain MCP server.