Eden: Let's discuss what's flow engineering, which is a new idea that has recently been discussed in the generative AI community. Now I warn you in advance, this is a very theoretical video and the idea of flow engineering is pretty abstract and not yet formalized to the end. So I don't expect you to understand everything in this video, but I promise you, by the end of this course, you'll know exactly what flow engineering is all about. Flow engineering is a systematic and strategic approach for developing software that will incorporate AI-driven decision-making processes. The essential goal of flow engineering is to manage and optimize how AI systems with LLMs handle tasks by defining a clear flow or a sequence of operations. These flows are not merely linear, so they may involve complex decision-making nodes where the AI may generate multiple outputs, which are often assessed and refined in an iterative cycle. Flow engineering is a structured process in AI development systems which guides the AI through a series of well-defined steps in order to improve the output quality of the AI system. Flow engineering aims to incorporate systematic planning and testing phase that mimic human development processes, and all of this to enhance reliability and functionality of AI-generated solutions. One of the issues with AutoGPT and other autonomous agents projects like BabyAGI, they are long-term planning. So they receive a goal, something to achieve, and then they start breaking it down to tasks, and then they start implementing and executing those tasks and derive subtasks of those tasks and so on and so on. And de facto, they aren't really working. So the point here is that we as developers want to give the instructions of what to do. We don't want the AI to start going and creating some imaginary attempts and start executing them. This is highly prone for problems and for the LLM to simply go out of hand. We as developers want to tell the LLM exactly what to do. We want to define the tasks and we want the LLM to stay within the context of those tasks. There are still decisions the LLM could make. For example, determining if the output is ready to be released and if it's a good enough solution or which step now to take. However, we, as developers, we define the scope and we do most of the planning for the LLM and the LLM can work within the flow that we have created. We give the LLM the blueprints to follow. And if we think about it as a state machine, we, as developers, we write the states. So we write what is the flow and what's need to be done, and what steps do we have. However, we can incorporate an LLM to decide which flow to take based on the input it gets. For example, whether to curate an answer or to simply release it to the user. And in the state machine is whether to go to step i, or maybe to i plus two, or whatever. So the state machine is an engineering decision, and no statistics is involved there. And LangGraph in the context of flow engineering is implementing this middle ground. It's the intermediate between fully autonomous agents that can decide what to do and how to do it and the LangChain chain, which is fully deterministic and there is no flexibility within this flow. So with flow engineering, we can achieve complex agentic solutions which will require us to build a state machine to define the steps of our flow. And we can use an LLM to either be a part of the step, for example, to make an LLM call to generate a tweet, and it can also be something that will tell us which steps to go to. So we leverage the LLM to do stuff within a step and we can leverage the LLM to decide which step to go. But the point here is that we, as developers, we define the flow and we have full control of it. And in LangGraph we can define graphs, and those are going to be nodes and edges, and we can have cycles in them, and we can build, and we'll do this in the course, very advanced logic that will give us a very complex AI system. And this is an example of a graph that is going to write a tweet, but it's going to also reflect and critique this tweet and do this in iterations until we get a very nice Twitter post. I believe that in the near future when we'll develop AI software and generative AI software, then the time we'll spend on the software will distribute the following. 60% is going to go to flow engineering and into architecture, the state machine, the nodes of what steps can we make, maybe we can incorporate an LLM within them and maybe even the LLM can decide which step to do. However, 35% will go to fine-tuning, so to make the model very specific for the tasks that we need to achieve. And 5% will be dedicated to prompt engineering. Alrighty. So I know that this video was super abstract and you probably didn't understand everything. Don't worry. I know this is a new topic and it's kind of ambiguous. However, I promise you that by the end of this course, you'll know exactly what flow engineering is and you'll understand why it is so important when we build those advanced agents using flow engineering techniques.