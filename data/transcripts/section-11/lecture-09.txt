All right. Let's go to notes and let's go and import from env the load env function. And now let's go and import the primitives from graph. So we want to import from graph. Graph. We want to import the messages state. And this is a simple object which has the dictionary of the key messages. And that messages is going to be a list of messages. So this is going to keep track on the state on all of the messages back in between our agent. So the human message and the AI message. All right. So now we want to import from graph prebuilt a prebuilt node which is called tool node. And this is a node. And I elaborate on this in the graph course which is going to execute tools. So it's going to check the last message between the agent and human. And if that last message is an I message that has a valid tool call, it's going to go and execute that tool code, assuming that tools is initiated with the tool node object. So if the agent decides to execute a search or decides to run the triple function, then those are going to run inside this tool node. And it will all be clear when we'll use it in action. All right. So we want to import from react the LM with the tool calls that we binded to and the list of tools that we defined in the react py file. All right. Let's load the environment variables. And let's implement now the reasoning engine of our agent. So basically it's going to be a node where the agent is going to receive our message. And it's going to decide whether it can answer it. Or it needs to invoke a tool. And it's going to arrange all the arguments for that too. So for that, we'll define a system message. And here we'll give the very generic system message of you are a helpful assistant with access to tools and that you can use to answer the question. And now let's go and define the first node which is going to be the agent reasoning node. So it's going to receive the state which is a message state which is a dictionary that has the key of messages. And here all that we're going to do is simply make an LM call with the user input. And the LM call is going to do all of the heavy lifting because the LM is binded with the tools. And we're going to leverage function calling here. So we're going to invoke the LM and the invocation. We're simply going to put here the role of a system. We're going to put the system message. And then we're going to put all of the messages that we have. So in the first iteration, we're going to have only the human message. In the second iteration, we're going to have also the human message and the response and so on and so on. So all the information is going to be in the messages state over here. So I'm going to access the messages key in the state. And right now I'm accessing it as a Python property. But let me go and change it soon to access a dictionary key instead just to be on the safe side. And this is going to send the human message. It's going to send it back to the LM. And then the LM decides whether we need to use a function call and execute a function, or it decides that it can output the answer. So after the node runs, we need to update our state. And if we'll return a dictionary with the key of messages and return here a list. And that list is going to have the response from the LM. So this is going to be the AI message here then is going to append this value to our state in the messages key. So the key has all the messages so far. And this node is going to update it. And it's going to add another message here. So we're done with the reasoning node. And we also need to define the node with the relevant tools. So this is going to help Landgraf execute the tools that we need. So let me define a variable called tool node. And it's going to be object of the class tool node from Landgraf prebuilt. And we're going to provide it with the tools that we defined the search and the multiply tools which are both link chain tools. So this node over here does a lot of heavy lifting. It can run tools in parallel, can run them in streaming mode. And it has a lot of cool functionality. But right now we're going to use the vanilla version. And by the way, I go deep into the implementations of this in my course. And before we had this object, it was actually a lot of boilerplate code to write just to run the tools in our graph. All right, let me go and commit now all the changes. And let me add this notepad file and I'll call this commit notes. Let me push it to the repo. And if you want you can go to the repository. Go to the notes commit. And here you have the code that we just wrote right. So we finished implementing the graph nodes. And we didn't implement a lot because we used a lot of language primitives, which saves us a lot of boilerplate code to run. And we are using the function calling features of LM methods. So the LM is going to do the reasoning for us. We don't really need to do anything here. We don't need to write a special prompt. We don't need to do any of this. And in the next video we're going to stitch everything together and implement our graph.