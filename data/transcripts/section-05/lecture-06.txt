Hey there, Eden here. Just a quick checking and I made this video in order to address some feedback I got from students that tried to integrate different LLMs and got confused a bit with the stop arguments for those different LLM providers. So, I hope this video will clarify this. So, in order to prevent parsing errors, we should always check our template isn't indented and to use the correct stop arguments for our LLM. So, this can change regarding which models you're using. When I made this video, just using \nObservation worked for me. And you might want to add also Observation without anything and you might want to try as well Observation:. And notice for some models like Chat OpenAI, then according to LangChain's newest version, you can bind this top argument with the bind method like you see over here. And because every vendor updates their SDK in different times, then if you're using Gemini, for example, currently, you need to use the model_kwargs argument. And if you want to be on the safe side, you can simply put all of those top tokens to cover all the cases because it's really sensitive even for those indents here. So, if you get a parse error about both a final answer and a parse-able action, it's almost always because of an indentation in the prompt template itself, or there's something wrong with the stop tokens here. So, this is very, very important. And if you're having issues, I recommend you checking the featured question of this video here. This might help for you. And also, it's important to note that after this section, I created an exercise for you where we'll be migrating from the react pattern to function calling. And by doing function calling, we're going to resolve this issue because we're going to shift the tool calling to the LLM, but more on that when you finish this section and you'll do the exercise. So, things have become more elegant, but this is the basis for everything.