Hey, they're eating here. Just a quick checking. And I made this video in order to address some feedback I got from students that try to integrate different lens, and got confused a bit with the stock arguments for those different LM providers. So I hope this video will clarify this. So in order to prevent parsing errors, we should always check our template isn't indented and to use the correct stop arguments for our LM. So this can change regarding which models you're using. When I made this video, just using backslash n observation worked for me. And you might want to add also observation without anything and you might want to try as well. Observation column and notice for some models like chat OpenAI. Then according to Link chains newest version, you can bind this argument with the bind method like you see over here. And because every vendor updates their SDK in different times, then if you're using Gemini, for example, currently you need to use the model query Quarrels. Argument. And if you want to be on the safe side, you can simply put all of those top tokens to cover all the cases because it's really sensitive, even for those in dense here. So if you get a parse error about both a final answer and a possible action, it's almost always because of an indentation in the prompt template itself. Or there's something wrong with the stop tokens here. So this is very, very important. And if you're having issues I recommend you checking in the featured question of this video here. Um, this might help for you. And also it's important to note that after this section, I created an exercise for you where we'll be migrating from the react pattern to function calling. And by doing function calling we're going to resolve this issue because we're going to shift the tool calling to the LM. But more on that when you finish this section and you'll do the exercise. So things have become more elegant. But this is the basis for everything.