Cool, so let's check out what we get and then you'll understand what's happening. Alright, so here we can see that we have here the answer. Now let me show you now the result, which is going to be the result of the agent execution. So in the result here, we have here an answer and we have here the context. So you can see the context here are a bunch of documents and we can see their IDs and we can see what are their sources, this metadata and those are going to be the documents which help us come up with the answer. Here we can see the answer. Now let me show you where everything came from, alright? Alright, so let's go and debug this. So I'm going to put a break point. Let's go and put a break point here and let me go and run it in debug mode. Cool, so we got here, and let's go and check out what happened after we invoked here, this agent. So let's go and check this response variable here because this is going to be holding the entire information, all of the information we need. Alright, so let's go and check out the response object. And here we're going to have a list of messages. The first message is going to be our input, which was "What are deep agents?" And you can see we reacted as a human message. LangChain, I remind you, it's converted it into a human message object by itself. Then it had a tool call. We can see now this AI message is a tool call which wants to invoke the retrieve context tool. So we can see here this is a tool call which want to use the retrieve context tool and this is the query it's going to send it and we have the ID and everything. And now LangChain is going to be executing this tool call. So after the tool call, we are getting a tool message. So this tool message is going to contain this tool response here. So the result of the tool execution. Now because we used the response format of content and artifact, we are returning here two values. This is going to be the content and this is going to be the artifact. So right here in the tool message here, if I'm going to go to the content attribute, we can see here this string here and we can see it starts with source, then it's going to have the sources and then it's going to have the content of the pages themselves. So this is this serialized string we formatted nicely which this we want to downstream into the LLM. And then we have now the retrieved docs here and this is going to be the artifact. So here we are going to have an artifact. Let's go and look for the artifact. Here you go. An artifact here is going to be a list of the documents. So this is the document, this is the page content about deep agents and why this is important and why did we do it. Because you see this list of messages over here? So when we actually go and send it to the LLM, the artifact is something we are not sending to the LLM. This is something for us to use in the application we're going to be building as another place to keep results here. So this is why it's convenient. So it's not going to pollute the context because we have already the sources, we have already documents, we don't really need them. But if we want to have a pythonic object we can work with to do later in the application maybe to render it nicely. So this is why it's used for. So just to reiterate on this, this tool message here, when we make a call to the LLM, the artifact is not being sent. So here this artifact, which is a list of documents, it's not going to be sent to the LLM. Cool, so we got to this breakpoint over here and here we simply formatting it nicely. We're taking the answer from the last place of the messages, you can see it right over here, and sending the context key with context doc and this is later, we can go and use it in our frontend maybe to render it nicely here. And let me go and finish here this execution. And here we can see all of the documents which are printed and here we can see the answer. Deep agent is a term LangChain coined for agents that can handle a complex open-ended tasks over longer time horizons. So now let me go and open LangSmith and let's see the trace. So when we're going to be seeing the trace here, it's going to be much more readable. So here I can open here this trace and we can see this ran under LangGraph because eventually it's going to be a LangGraph graph. This is the human input, "What are deep agents?" Then we went to the model. The model decided that we want to make a tool call. Okay, here is the system message. So the tool call was to retrieve context with the query of LangChain's deep agent's definition. This is cool. So it actually rephrased my question. So it searched in the vector store deep agent definition, not what are deep agents. So this is also nice to see. Then LangChain went and ran the tool and here you can see we used the retrieve context tool. So here we can see that we are using the retriever and we find the relevant documents to answer the question here. You can see this is the documents content, this is the source attribute which we made sure is going to be valid when we indexed the documents from before. And I want to show you something. If we go to the LangChain RAG agent documentation. Let's go here and let's look for the snippets right over here. Here we go. So here you can see what in the docs they're doing, they're using the vector store as is and they're using its raw similarity search tool, okay? Now we use the as retriever. Now this difference, and I urge you, go and try to see for yourself the difference why I used here the as retriever is because it's going to render much more nicely in LangSmith. Because if we were to simply use the vector store similarity search, then this won't be indexed as nicely in LangSmith in the tracing. So eventually we got here after the tool execution, we got here the docs. And if we'll go and check out this view over here, we can even see our LangGraph state under the hood. I know we haven't learned about LangGraph, but this is in case you want to see it. And don't worry we're going to be covering later in the course. Here we made the final LLM call. So this was the original prompt. It had now the history that we used the retrieve context tool, then we have the tool information here, the tool execution results. And finally it used this to render the answer. And here we have the answer here. And let's go and check out what are deep agents. And here we can see the blog on deep agents which we're going to be covering in the course as well. Alright, so let me go and commit this to the repo. So let me go and write, "updated retrieval to latest LangChain code." and let me go and push it. Alright, and if you want to check out the code for this video, you can go to the branch 2-retrieval-qa-finish. And you can see here if you'll go to backend/core.py, this is what we did right now.